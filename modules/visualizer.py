# modules/visualizer.py
#--- Importaciones Est谩ndar y de Terceros
import streamlit as st
import pandas as pd
import base64
import geopandas as gpd
import altair as alt
import folium
from folium.plugins import MarkerCluster, MiniMap
from folium.raster_layers import WmsTileLayer
from streamlit_folium import folium_static
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
import branca.colormap as cm
import matplotlib.pyplot as plt
import pymannkendall as mk
from scipy import stats
from prophet.plot import plot_plotly
import io
#--- Importaciones de M贸dulos Propios
from modules.analysis import (
    calculate_spi, calculate_spei, calculate_monthly_anomalies,
    calculate_percentiles_and_extremes, analyze_events,
    calculate_climatological_anomalies
)
from modules.config import Config
from modules.utils import add_folium_download_button
from modules.interpolation import create_interpolation_surface
from modules.forecasting import (
    generate_sarima_forecast, generate_prophet_forecast,
    get_decomposition_results, create_acf_chart, create_pacf_chart
)
#--- FUNCIONES DE UTILIDAD DE VISUALIZACIN
def display_filter_summary(total_stations_count, selected_stations_count, year_range,
                           selected_months_count, analysis_mode, selected_regions, selected_municipios, selected_altitudes):
    """Muestra una caja informativa con un resumen de todos los filtros aplicados."""
    if isinstance(year_range, tuple) and len(year_range) == 2:
        year_text = f"{year_range[0]}-{year_range[1]}"
    else:
        year_text = "N/A"
    mode_text = "Serie Completada" if "Completar" in analysis_mode else "Serie Original"
    summary_parts = [
        f"**Estaciones:** {selected_stations_count}/{total_stations_count}",
        f"**Per铆odo:** {year_text}",
        f"**Datos:** {mode_text}"
    ]
    if selected_regions:
        summary_parts.append(f"**Regi贸n:** {', '.join(selected_regions)}")
    if selected_municipios:
        summary_parts.append(f"**Municipio:** {', '.join(selected_municipios)}")
    if selected_altitudes:
        summary_parts.append(f"**Altitud:** {', '.join(selected_altitudes)}")
    st.info(" | ".join(summary_parts))

def get_map_options():
    """Retorna un diccionario con las configuraciones de los mapas base y capas."""
    return {
        "CartoDB Positron (Predeterminado)": {"tiles": "cartodbpositron", "attr": '&copy; <a href="https://carto.com/attributions">CartoDB</a>', "overlay": False},
        "OpenStreetMap": {"tiles": "OpenStreetMap", "attr": '&copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors', "overlay": False},
        "Topograf铆a (Open TopoMap)": {"tiles": "https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png", "attr": 'Map data: &copy; <a href="https://www.openstreetmap.org/copyright"> OSM</a> contributors, <a href="http://viewfinderpanoramas.org">SRTM</a> | Map style: &copy; <a href="https://opentopomap.org">OpenTopoMap</a>', "overlay": False},
        "Mapa de Colombia (WMS IDEAM)": {"url": "https://geoservicios.ideam.gov.co/geoserver/ideam/wms", "layers": "ideam:col_admin", "transparent": True, "attr": "IDEAM", "overlay": True},
    }

def display_map_controls(container_object, key_prefix):
    """Muestra los controles para seleccionar mapa base y capas en Streamlit."""
    map_options = get_map_options()
    base_maps = {k: v for k, v in map_options.items() if not v.get("overlay")}
    overlays = {k: v for k, v in map_options.items() if v.get("overlay")}
    
    selected_base_map_name = container_object.selectbox("Seleccionar Mapa Base", list(base_maps.keys()), key=f"{key_prefix}_base_map")
    default_overlays = ["Mapa de Colombia (WMS IDEAM)"]
    selected_overlays_names = container_object.multiselect("Seleccionar Capas Adicionales", list(overlays.keys()), default=default_overlays, key=f"{key_prefix}_overlays")
    
    selected_overlays_config = [overlays[k] for k in selected_overlays_names]
    return base_maps[selected_base_map_name], selected_overlays_config

def create_enso_chart(enso_data):
    if enso_data.empty or Config.ENSO_ONI_COL not in enso_data.columns:
        return go.Figure()

    data = enso_data.copy().sort_values(Config.DATE_COL)
    data.dropna(subset=[Config.ENSO_ONI_COL], inplace=True)

    if data.empty:
        return go.Figure()

    conditions = [data[Config.ENSO_ONI_COL] >= 0.5, data[Config.ENSO_ONI_COL] <= -0.5]
    phases = ['El Ni帽o', 'La Ni帽a']
    colors = ['red', 'blue']
    data['phase'] = np.select(conditions, phases, default='Neutral')
    data['color'] = np.select(conditions, colors, default='grey')

    y_range = [data[Config.ENSO_ONI_COL].min() - 0.5, data[Config.ENSO_ONI_COL].max() + 0.5]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=data[Config.DATE_COL],
        y=[y_range[1] - y_range[0]] * len(data),
        base=y_range[0],
        marker_color=data['color'],
        width=30*24*60*60*1000,
        opacity=0.3,
        hoverinfo='none',
        showlegend=False
    ))

    legend_map = {'El Ni帽o': 'red', 'La Ni帽a': 'blue', 'Neutral': 'grey'}
    for phase, color in legend_map.items():
        fig.add_trace(go.Scatter(
            x=[None], y=[None], mode='markers',
            marker=dict(size=15, color=color, symbol='square', opacity=0.5),
            name=phase, showlegend=True
        ))

    fig.add_trace(go.Scatter(
        x=data[Config.DATE_COL], y=data[Config.ENSO_ONI_COL],
        mode='lines', name='Anomal铆a ONI', line=dict(color='black', width=2), showlegend=True
    ))

    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    fig.add_hline(y=-0.5, line_dash="dash", line_color="blue")

    fig.update_layout(
        height=600, title="Fases del Fen贸meno ENSO y Anomal铆a ONI",
        yaxis_title="Anomal铆a ONI (掳C)", xaxis_title="Fecha",
        showlegend=True, legend_title_text='Fase', yaxis_range=y_range
    )
    return fig

def create_anomaly_chart(df_plot):
    if df_plot.empty:
        return go.Figure()

    df_plot['color'] = np.where(df_plot['anomalia'] < 0, 'red', 'blue')
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=df_plot[Config.DATE_COL], y=df_plot['anomalia'],
        marker_color=df_plot['color'], name='Anomal铆a de Precipitaci贸n'
    ))

    if Config.ENSO_ONI_COL in df_plot.columns:
        df_plot_enso = df_plot.dropna(subset=[Config.ENSO_ONI_COL])
        
        nino_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] >= 0.5]
        for _, row in nino_periods.iterrows():
            fig.add_vrect(
                x0=row[Config.DATE_COL] - pd.DateOffset(days=15), x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                fillcolor="red", opacity=0.15, layer="below", line_width=0
            )
            
        nina_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] <= -0.5]
        for _, row in nina_periods.iterrows():
            fig.add_vrect(
                x0=row[Config.DATE_COL] - pd.DateOffset(days=15), x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                fillcolor="blue", opacity=0.15, layer="below", line_width=0
            )

        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers', marker=dict(symbol='square', color='rgba(255, 0, 0, 0.3)'), name='Fase El Ni帽o'))
        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers', marker=dict(symbol='square', color='rgba(0, 0, 255, 0.3)'), name='Fase La Ni帽a'))

    fig.update_layout(
        height=600, title="Anomal铆as Mensuales de Precipitaci贸n y Fases ENSO",
        yaxis_title="Anomal铆a de Precipitaci贸n (mm)", xaxis_title="Fecha", showlegend=True
    )
    return fig

# --- FUNCIONES AUXILIARES PARA POPUPS ---
def generate_station_popup_html(row, df_anual_melted, include_chart=False, df_monthly_filtered=None):
    """Genera el contenido HTML para el popup de una estaci贸n, incluyendo un mini-gr谩fico opcional."""
    station_name = row.get(Config.STATION_NAME_COL, 'N/A')
    try:
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        year_min, year_max = year_range_val
        total_years_in_period = year_max - year_min + 1
        
        df_station_data = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_name]
        
        precip_media_anual = df_station_data['precipitation'].mean() if not df_station_data.empty else 0
        valid_years = df_station_data['precipitation'].count() if not df_station_data.empty else 0
        precip_formatted = f"{precip_media_anual:.0f}" if pd.notna(precip_media_anual) else "N/A"
            
        text_html = f"<h4>{station_name}</h4>"
        text_html += f"<p><b>Municipio:</b> {row.get(Config.MUNICIPALITY_COL, 'N/A')}</p>"
        text_html += f"<p><b>Altitud:</b> {row.get(Config.ALTITUDE_COL, 'N/A')} m</p>"
        text_html += f"<p><b>Promedio Anual:</b> {precip_formatted} mm</p>"
        text_html += f"<small>(Calculado con <b>{valid_years}</b> de <b>{total_years_in_period}</b> a帽os del per铆odo)</small>"
        
        full_html = text_html
        
        chart_html = ""
        if include_chart and df_monthly_filtered is not None:
            df_station_monthly = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_name]
            if not df_station_monthly.empty:
                df_monthly_avg = df_station_monthly.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                if not df_monthly_avg.empty:
                    fig = go.Figure(data=[go.Bar(x=df_monthly_avg[Config.MONTH_COL], y=df_monthly_avg[Config.PRECIPITATION_COL])])
                    fig.update_layout(title_text="Ppt. Mensual Media", xaxis_title="Mes", yaxis_title="Ppt. (mm)", height=250, width=350, margin=dict(t=40, b=20, l=20, r=20))
                    chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')
        
        if chart_html:
            sanitized_chart_html = chart_html.replace('"', '&quot;')
            full_html = text_html + "<hr>" + f'<iframe srcdoc="{sanitized_chart_html}" width="370" height="270" frameborder="0"></iframe>'
            
    except Exception as e:
        st.warning(f"No se pudo generar el popup para '{station_name}'. Raz贸n: {e}")
        full_html = f"<h4>{station_name}</h4><p>Error al cargar datos del popup.</p>"
            
    return folium.Popup(full_html, max_width=450)

def generate_compare_map_popup_html(row, df_anual_melted_full_period):
    """Genera un popup espec铆fico para los mapas de comparaci贸n."""
    station_name = row.get(Config.STATION_NAME_COL, 'N/A')
    municipality = row.get(Config.MUNICIPALITY_COL, 'N/A')
    altitude = row.get(Config.ALTITUDE_COL, 'N/A')
    precip_year = row.get(Config.PRECIPITATION_COL, 'N/A')
    
    station_full_data = df_anual_melted_full_period[df_anual_melted_full_period[Config.STATION_NAME_COL] == station_name]
    precip_avg, precip_max, precip_min = "N/A", "N/A", "N/A"
    if not station_full_data.empty:
        precip_avg = f"{station_full_data[Config.PRECIPITATION_COL].mean():.0f}"
        precip_max = f"{station_full_data[Config.PRECIPITATION_COL].max():.0f}"
        precip_min = f"{station_full_data[Config.PRECIPITATION_COL].min():.0f}"

    altitude_formatted = f"{altitude:.0f}" if isinstance(altitude, (int, float)) and np.isfinite(altitude) else "N/A"
    precip_year_formatted = f"{precip_year:.0f}" if isinstance(precip_year, (int, float)) and np.isfinite(precip_year) else "N/A"

    html = f"""
    <h4>{station_name}</h4>
    <p><b>Municipio:</b> {municipality}</p>
    <p><b>Altitud:</b> {altitude_formatted} m</p>
    <p><b>Promedio Anual (per铆odo):</b> {precip_avg} mm</p>
    <hr>
    <p><b>Precipitaci贸n del A帽o:</b> {precip_year_formatted} mm</p>
    <p><small><b>M谩xima del per铆odo:</b> {precip_max} mm</small></p>
    <p><small><b>M铆nima del per铆odo:</b> {precip_min} mm</small></p>
    """
    return folium.Popup(html, max_width=300)

def generate_temporal_map_popup_html(row, df_anual_melted_full_period):
    """Genera un popup espec铆fico para el mapa de visualizaci贸n temporal."""
    station_name = row.get(Config.STATION_NAME_COL, 'N/A')
    municipality = row.get(Config.MUNICIPALITY_COL, 'N/A')
    altitude = row.get(Config.ALTITUDE_COL, 'N/A')
    precip_year = row.get(Config.PRECIPITATION_COL, 'N/A')

    station_full_data = df_anual_melted_full_period[df_anual_melted_full_period[Config.STATION_NAME_COL] == station_name]
    precip_max, precip_min, precip_avg = "N/A", "N/A", "N/A"
    if not station_full_data.empty:
        precip_avg = f"{station_full_data[Config.PRECIPITATION_COL].mean():.0f}"
        precip_max = f"{station_full_data[Config.PRECIPITATION_COL].max():.0f}"
        precip_min = f"{station_full_data[Config.PRECIPITATION_COL].min():.0f}"

    altitude_formatted = f"{altitude:.0f}" if isinstance(altitude, (int, float)) and np.isfinite(altitude) else "N/A"
    precip_year_formatted = f"{precip_year:.0f}" if isinstance(precip_year, (int, float)) and np.isfinite(precip_year) else "N/A"

    html = f"""
    <h4>{station_name}</h4>
    <p><b>Municipio:</b> {municipality}</p>
    <p><b>Altitud:</b> {altitude_formatted} m</p>
    <p><b>Promedio Anual (per铆odo):</b> {precip_avg} mm</p>
    <hr>
    <p><b>Precipitaci贸n del A帽o:</b> {precip_year_formatted} mm</p>
    <p><small><b>M谩xima del per铆odo:</b> {precip_max} mm</small></p>
    <p><small><b>M铆nima del per铆odo:</b> {precip_min} mm</small></p>
    """
    return folium.Popup(html, max_width=300)

def create_folium_map(location, zoom, base_map_config, overlays_config, fit_bounds_data=None):
    """Creates a Folium map with robust centering logic."""
    m = folium.Map(location=location, zoom_start=zoom, tiles=base_map_config.get("tiles", "OpenStreetMap"), attr=base_map_config.get("attr", None))
    if fit_bounds_data is not None and not fit_bounds_data.empty:
        if len(fit_bounds_data) > 1:
            bounds = fit_bounds_data.total_bounds
            if np.all(np.isfinite(bounds)):
                m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
        elif len(fit_bounds_data) == 1:
            point = fit_bounds_data.iloc[0].geometry
            m.location = [point.y, point.x]
            m.zoom_start = 12
    for layer_config in overlays_config:
        if layer_config.get("url"):
            WmsTileLayer(
                url=layer_config["url"], layers=layer_config["layers"], fmt='image/png',
                transparent=layer_config.get("transparent", False), overlay=True, control=True,
                name=layer_config.get("attr", "Overlay")
            ).add_to(m)
    return m

# --- MAIN TAB DISPLAY FUNCTIONS

def display_welcome_tab():
    st.header("Bienvenido al Sistema de Informaci贸n de Lluvias y Clima")
    st.markdown(Config.WELCOME_TEXT, unsafe_allow_html=True)
    
    if os.path.exists(Config.LOGO_PATH):
        try:
            st.image(Config.LOGO_PATH, width=250, caption="Corporaci贸n Cuenca Verde")
        except Exception:
            st.warning("No se pudo cargar el logo de bienvenida.")

    st.markdown("---")

    # --- NUEVO MDULO DE CONCEPTOS CLAVE ---
    with st.expander(" Conceptos Clave, M茅todos y Ecuaciones"):
        st.markdown("""
        Esta secci贸n proporciona una breve descripci贸n de los m茅todos y conceptos anal铆ticos utilizados en la plataforma.

        ### M茅todos de Interpolaci贸n Espacial
        La interpolaci贸n se usa para estimar la precipitaci贸n en lugares donde no hay estaciones de medici贸n, creando superficies continuas (mapas).
        - **IDW (Inverso de la Distancia Ponderada)**: Un m茅todo simple que asume que los puntos m谩s cercanos tienen m谩s influencia que los lejanos. El valor en un punto desconocido es un promedio ponderado de los valores conocidos, donde el peso es inversamente proporcional a la distancia.
        - **Kriging**: Un m茅todo geoestad铆stico avanzado que utiliza la autocorrelaci贸n espacial entre los puntos (descrita por un **variograma**) para realizar estimaciones. A diferencia de IDW, proporciona una estimaci贸n del error de predicci贸n.
            - **Ordinario (OK)**: Asume que la media del campo es desconocida pero constante.
            - **Con Deriva Externa (KED)**: Incorpora una variable secundaria (covariable), como la elevaci贸n de un Modelo Digital de Elevaci贸n (DEM), para mejorar las predicciones.
        - **Spline (Thin Plate)**: Un m茅todo matem谩tico que ajusta una superficie flexible a trav茅s de los puntos de datos, minimizando la curvatura total. Es 煤til para superficies que cambian suavemente.

        ### ndices de Sequ铆a
        Estos 铆ndices estandarizan la precipitaci贸n para monitorear condiciones de sequ铆a y humedad a lo largo del tiempo.
        - **SPI (ndice de Precipitaci贸n Estandarizado)**: Mide las desviaciones de la precipitaci贸n con respecto a su media hist贸rica. Se ajusta a una distribuci贸n de probabilidad (Gamma) y luego se transforma a una distribuci贸n normal. Un valor de -1.5 indica una sequ铆a moderada, mientras que +1.5 indica un per铆odo muy h煤medo.
        - **SPEI (ndice Estandarizado de Precipitaci贸n-Evapotranspiraci贸n)**: Es similar al SPI, pero se basa en el **balance h铆drico clim谩tico** (Precipitaci贸n menos Evapotranspiraci贸n Potencial). Es m谩s completo para sequ铆as agr铆colas, ya que considera el efecto de la temperatura.

        ### An谩lisis de Tendencias
        Se utilizan para determinar si los valores de precipitaci贸n han aumentado, disminuido o permanecido constantes a lo largo del tiempo.
        - **Prueba de Mann-Kendall**: Una prueba no param茅trica que eval煤a la existencia de una tendencia mon贸tona (siempre creciente o decreciente) en una serie de tiempo. No requiere que los datos sigan una distribuci贸n normal.
        - **Pendiente de Sen**: Un m茅todo robusto para cuantificar la magnitud de la tendencia. Calcula la mediana de todas las pendientes entre pares de puntos en la serie, lo que lo hace menos sensible a valores at铆picos. La ecuaci贸n de la l铆nea de tendencia es:
        $$ y(t) = Q \cdot t + B $$
        Donde $Q$ es la Pendiente de Sen y $B$ es una constante.

        ### Modelos de Pron贸stico
        - **SARIMA (Seasonal AutoRegressive Integrated Moving Average)**: Un modelo estad铆stico cl谩sico para series de tiempo que descompone los datos en componentes autorregresivos (AR), de media m贸vil (MA) e integrados (I), junto con sus contrapartes estacionales (S). Se define por los par谩metros $(p, d, q)(P, D, Q)_s$.
        - **Prophet**: Un modelo desarrollado por Facebook, dise帽ado para ser m谩s autom谩tico y robusto. Modela la serie de tiempo como una suma de componentes:
        $$ y(t) = g(t) + s(t) + h(t) + \epsilon_t $$
        Donde $g(t)$ es la tendencia, $s(t)$ la estacionalidad (anual, semanal), $h(t)$ el efecto de d铆as festivos o eventos especiales, y $\epsilon_t$ el t茅rmino de error.
        """)

def display_spatial_distribution_tab(gdf_filtered, stations_for_analysis, df_anual_melted, df_monthly_filtered, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("Distribuci贸n espacial de las Estaciones de Lluvia")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    gdf_display = gdf_filtered.copy()
    if not df_anual_melted.dropna (subset=[Config. PRECIPITATION_COL]).empty:
        summary_stats = df_anual_melted.groupby (Config.STATION_NAME_COL) [Config.PRECIPITATION_COL].agg(['mean', 'count']).reset_index()
        summary_stats.rename(columns={'mean': 'precip_media_anual', 'count': 'a帽os_validos'}, inplace=True)
        gdf_display = gdf_display.merge(summary_stats, on=Config.STATION_NAME_COL, how='left')
    else:
        gdf_display['precip_media_anual'] = np.nan
        gdf_display['a帽os_validos'] = 0
    gdf_display['precip_media_anual'] = gdf_display['precip_media_anual'].fillna(0)
    gdf_display['a帽os_validos'] = gdf_display['a帽os_validos'].fillna(0).astype(int)
    sub_tab_mapa, sub_tab_grafico = st.tabs(["Mapa Interactivo", "Gr谩fico de Disponibilidad de Datos"])
    with sub_tab_mapa:
        controls_col, map_col = st.columns([1, 3])
        with controls_col:
            st.subheader("Controles del Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st, "dist_esp")
            if not gdf_display.empty:
                st.markdown("---")
                st.metric("Estaciones en Vista", len(gdf_display))
                st.markdown("---")
                if os.path.exists(Config.LOGO_PATH):
                    try:
                        with open(Config.LOGO_PATH, "rb") as f: logo_bytes = f.read()
                        st.image(logo_bytes, width = 70)
                    except Exception: st.warning("No se pudo cargar el logo.")
        with map_col:
            if not gdf_display.empty:
                m = create_folium_map(location=[4.57, -74.29], zoom=5, base_map_config=selected_base_map_config, overlays_config=selected_overlays_config, fit_bounds_data=gdf_display)
                if 'gdf_municipios' in st.session_state and st.session_state.gdf_municipios is not None:
                    folium.GeoJson(st.session_state.gdf_municipios.to_json(), name='Municipios').add_to(m)
                marker_cluster = MarkerCluster(name='Estaciones').add_to(m)
                for _, row in gdf_display.iterrows():
                    popup_object = generate_station_popup_html(row, df_anual_melted, include_chart=False)
                    folium.Marker(location=[row['geometry'].y, row['geometry'].x], tooltip=row[Config.STATION_NAME_COL], popup=popup_object).add_to(marker_cluster)
                folium.LayerControl().add_to(m)
                m.add_child(MiniMap(toggle_display=True))
                folium_static(m, height=450, width=None)
                add_folium_download_button(m, "mapa_distribucion.html")
            else:
                st.warning("No hay estaciones seleccionadas para mostrar en el mapa.")
    with sub_tab_grafico:
        st.subheader("Disponibilidad y Composici贸n de Datos por Estaci贸n")
        if not gdf_display.empty:
            if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
                st.info("Mostrando la composici贸n de datos originales vs. completados para el per铆odo seleccionado.")
                if not df_monthly_filtered.empty and Config.ORIGIN_COL in df_monthly_filtered.columns:
                    data_composition = df_monthly_filtered.groupby([Config.STATION_NAME_COL, Config.ORIGIN_COL]).size().unstack(fill_value=0)
                    if 'Original' not in data_composition: data_composition['Original'] = 0
                    if 'Completado' not in data_composition: data_composition['Completado'] = 0
                    data_composition['total'] = data_composition['Original'] + data_composition['Completado']
                    data_composition['% Original'] = (data_composition['Original'] / data_composition['total']) * 100
                    data_composition['% Completado'] = (data_composition['Completado'] / data_composition['total']) * 100
                    sort_order_comp = st.radio("Ordenar por:", ["% Datos Originales (Mayor a Menor)", "% Datos Originales (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_comp")
                    if "Mayor a Menor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=False)
                    elif "Menor a Mayor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=True)
                    else: data_composition = data_composition.sort_index(ascending=True)
                    df_plot = data_composition.reset_index().melt(id_vars=Config.STATION_NAME_COL, value_vars=['% Original', '% Completado'], var_name='Tipo de Dato', value_name='Porcentaje')
                    fig_comp = px.bar(
                        df_plot, x=Config.STATION_NAME_COL, y='Porcentaje', color='Tipo de Dato',
                        title='Composici贸n de Datos por Estaci贸n', labels={Config.STATION_NAME_COL: 'Estaci贸n', 'Porcentaje': '% del Per铆odo'},
                        text_auto='.1f', color_discrete_map={'% Original': '#1f77b4', '% Completado': '#ff7f0e'}
                    )
                    fig_comp.update_layout(height=500, xaxis={'categoryorder': 'trace'})
                    st.plotly_chart(fig_comp, use_container_width=True)
                else:
                    st.warning("No hay datos mensuales procesados para mostrar la composici贸n.")
            else:
                st.info("Mostrando el porcentaje de disponibilidad de datos seg煤n el archivo de estaciones.")
                sort_order_disp = st.radio("Ordenar estaciones por:", ["% Datos (Mayor a Menor)", "% Datos (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_disp")
                df_chart = gdf_display.copy()
                if "% Datos (Mayor a Menor)" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=False)
                elif "% Datos (Menor a Mayor)" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=True)
                else: df_chart = df_chart.sort_values(Config.STATION_NAME_COL, ascending=True)
                fig_disp = px.bar(
                    df_chart, x=Config.STATION_NAME_COL, y=Config.PERCENTAGE_COL, title='Porcentaje de Disponibilidad de Datos Hist贸ricos',
                    labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PERCENTAGE_COL: '% de Datos Disponibles'},
                    color=Config.PERCENTAGE_COL, color_continuous_scale=px.colors.sequential.Viridis
                )
                fig_disp.update_layout(height=500, xaxis={'categoryorder': 'trace'})
                st.plotly_chart(fig_disp, use_container_width=True)
        else:
            st.warning("No hay estaciones seleccionadas para mostrar el gr谩fico.")

def display_graphs_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis, gdf_filtered, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("Visualizaciones de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    year_range_val = st.session_state.get('year_range', (2000, 2020))
    if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
        year_min, year_max = year_range_val
    else:
        year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))

    metadata_cols = [Config.STATION_NAME_COL, Config.MUNICIPALITY_COL, Config.ALTITUDE_COL]
    gdf_metadata = gdf_filtered[metadata_cols].drop_duplicates(subset=[Config.STATION_NAME_COL]).copy()
    
    if Config.ALTITUDE_COL in gdf_metadata.columns:
        gdf_metadata[Config.ALTITUDE_COL] = pd.to_numeric(gdf_metadata[Config.ALTITUDE_COL], errors='coerce').fillna(-9999).astype(int).astype(str)
    if Config.MUNICIPALITY_COL in gdf_metadata.columns:
        gdf_metadata[Config.MUNICIPALITY_COL] = gdf_metadata[Config.MUNICIPALITY_COL].astype(str).str.strip().replace('nan', 'Sin Dato')
    
    cols_to_drop = [col for col in [Config.MUNICIPALITY_COL, Config.ALTITUDE_COL] if col != Config.STATION_NAME_COL]
    df_anual_pre_merge = df_anual_melted.drop(columns=cols_to_drop, errors='ignore')
    df_anual_rich = df_anual_pre_merge.merge(gdf_metadata, on=Config.STATION_NAME_COL, how='left')
    df_monthly_pre_merge = df_monthly_filtered.drop(columns=cols_to_drop, errors='ignore')
    df_monthly_rich = df_monthly_pre_merge.merge(gdf_metadata, on=Config.STATION_NAME_COL, how='left')
    
    sub_tab_anual, sub_tab_mensual, sub_tab_comparacion, sub_tab_distribucion, sub_tab_acumulada, sub_tab_altitud, sub_tab_regional = st.tabs([
        "An谩lisis Anual", "An谩lisis Mensual", "Comparaci贸n R谩pida", "Distribuci贸n",
        "Acumulada", "Relaci贸n Altitud", "Serie Regional"
    ])
    
    with sub_tab_anual:
        anual_graf_tab, anual_analisis_tab = st.tabs(["Gr谩fico de Serie Anual", "An谩lisis Multianual"])
        with anual_graf_tab:
            if not df_anual_rich.empty:
                st.subheader("Precipitaci贸n Anual (mm)")
                st.info("Solo se muestran los a帽os con 10 o m谩s meses de datos v谩lidos.")
                chart_anual = alt.Chart(df_anual_rich.dropna(subset=[Config.PRECIPITATION_COL])).mark_line(point=True).encode(
                    x=alt.X(f'{Config.YEAR_COL}:O', title='A帽o'), y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci贸n (mm)'),
                    color=f'{Config.STATION_NAME_COL}:N',
                    tooltip=[
                        alt.Tooltip(Config.STATION_NAME_COL), alt.Tooltip(Config.YEAR_COL, format='d', title='A帽o'),
                        alt.Tooltip(f'{Config.PRECIPITATION_COL}:Q', format='.0f', title='Ppt. Anual (mm)'),
                        alt.Tooltip(f'{Config.MUNICIPALITY_COL}:N', title='Municipio'), alt.Tooltip(f'{Config.ALTITUDE_COL}:N', title='Altitud (m)')
                    ]
                ).properties(title=f'Precipitaci贸n Anual por Estaci贸n ({year_min} - {year_max})').interactive()
                st.altair_chart(chart_anual, use_container_width=True)
            else:
                st.warning("No hay datos anuales para mostrar la serie.")
        with anual_analisis_tab:
            if not df_anual_rich.empty:
                st.subheader("Precipitaci贸n Media Multianual")
                st.caption(f"Per铆odo de an谩lisis: {year_min} - {year_max}")
                chart_type_annual = st.radio("Seleccionar tipo de gr谩fico:", ("Gr谩fico de Barras (Promedio)", "Gr谩fico de Cajas (Distribuci贸n)"), key="avg_chart_type_annual", horizontal=True)
                if chart_type_annual == "Gr谩fico de Barras (Promedio)":
                    df_summary = df_anual_rich.groupby(Config.STATION_NAME_COL, as_index=False)[Config.PRECIPITATION_COL].mean().round(0)
                    sort_order = st.radio("Ordenar estaciones por:", ["Promedio (Mayor a Menor)", "Promedio (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_annual_avg")
                    if "Mayor a Menor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=False)
                    elif "Menor a Mayor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=True)
                    else: df_summary = df_summary.sort_values(Config.STATION_NAME_COL, ascending=True)
                    fig_avg = px.bar(
                        df_summary, x=Config.STATION_NAME_COL, y=Config.PRECIPITATION_COL,
                        title=f'Promedio de Precipitaci贸n Anual por Estaci贸n ({year_min} - {year_max})',
                        labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PRECIPITATION_COL: 'Precipitaci贸n Media Anual (mm)'},
                        color=Config.PRECIPITATION_COL, color_continuous_scale=px.colors.sequential.Blues_r
                    )
                    fig_avg.update_layout(height=500, xaxis={'categoryorder': 'total descending' if "Mayor a Menor" in sort_order else ('total ascending' if "Menor a Mayor" in sort_order else 'trace')})
                    st.plotly_chart(fig_avg, use_container_width=True)
                else:
                    df_anual_filtered_for_box = df_anual_rich[df_anual_rich[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                    fig_box_annual = px.box(
                        df_anual_filtered_for_box, x=Config.STATION_NAME_COL, y=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL, points='all',
                        title='Distribuci贸n de la Precipitaci贸n Anual por Estaci贸n', labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)'}
                    )
                    fig_box_annual.update_layout(height=500)
                    st.plotly_chart(fig_box_annual, use_container_width=True, key="box_anual_multianual")
            else:
                st.warning("No hay datos anuales para mostrar el an谩lisis multianual.")

    with sub_tab_mensual:
        mensual_graf_tab, mensual_enso_tab, mensual_datos_tab = st.tabs(["Gr谩fico de Serie Mensual", "An谩lisis ENSO en el Per铆odo", "Tabla de Datos"])
        with mensual_graf_tab:
            if not df_monthly_rich.empty:
                controls_col, chart_col = st.columns([1, 4])
                with controls_col:
                    st.markdown("##### Opciones del Gr谩fico")
                    chart_type = st.radio("Tipo de Gr谩fico:", ["L铆neas y Puntos", "Nube de Puntos", "Gr谩fico de Cajas (Distribuci贸n Mensual)"], key="monthly_chart_type")
                    color_by_disabled = (chart_type == "Gr谩fico de Cajas (Distribuci贸n Mensual)")
                    color_by = st.radio("Colorear por:", ["Estaci贸n", "Mes"], key="monthly_color_by", disabled=color_by_disabled)
                with chart_col:
                    if chart_type != "Gr谩fico de Cajas (Distribuci贸n Mensual)":
                        base_chart = alt.Chart(df_monthly_rich).encode(
                            x=alt.X(f'{Config.DATE_COL}:T', title='Fecha'), y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci贸n (mm)'),
                            tooltip=[
                                alt.Tooltip(f'{Config.DATE_COL}:T', format='%Y-%m', title='Fecha'), alt.Tooltip(f'{Config.PRECIPITATION_COL}:Q', format='.0f', title='Ppt. Mensual'),
                                alt.Tooltip(f'{Config.STATION_NAME_COL}:N', title='Estaci贸n'), alt.Tooltip(f'{Config.MONTH_COL}:N', title="Mes"),
                                alt.Tooltip(f'{Config.MUNICIPALITY_COL}:N', title='Municipio'), alt.Tooltip(f'{Config.ALTITUDE_COL}:N', title='Altitud (m)')
                            ]
                        )
                        if color_by == "Mes": color_encoding = alt.Color(f'month({Config.DATE_COL}):N', legend=alt.Legend(title="Meses"), scale=alt.Scale(scheme='tableau20'))
                        else: color_encoding = alt.Color(f'{Config.STATION_NAME_COL}:N', legend=alt.Legend(title="Estaciones"))
                        if chart_type == "L铆neas y Puntos":
                            line_chart = base_chart.mark_line(opacity=0.4, color='lightgray').encode(detail=f'{Config.STATION_NAME_COL}:N')
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = (line_chart + point_chart)
                        else:
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = point_chart
                        st.altair_chart(final_chart.properties(height=500, title=f"Serie de Precipitaci贸n Mensual ({year_min} - {year_max})").interactive(), use_container_width=True)
                    else:
                        st.subheader("Distribuci贸n de la Precipitaci贸n Mensual")
                        fig_box_monthly = px.box(
                            df_monthly_rich, x=Config.MONTH_COL, y=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL, title='Distribuci贸n de la Precipitaci贸n por Mes',
                            labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'}
                        )
                        fig_box_monthly.update_layout(height=500)
                        st.plotly_chart(fig_box_monthly, use_container_width=True)
            else:
                st.warning("No hay datos mensuales para mostrar el gr谩fico.")
        with mensual_enso_tab:
            if 'df_enso' in st.session_state and st.session_state.df_enso is not None:
                enso_filtered = st.session_state.df_enso[(st.session_state.df_enso[Config.DATE_COL].dt.year >= year_min) & (st.session_state.df_enso[Config.DATE_COL].dt.year <= year_max) & (st.session_state.df_enso[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))]
                fig_enso_mensual = create_enso_chart(enso_filtered)
                st.plotly_chart(fig_enso_mensual, use_container_width=True, key="enso_chart_mensual")
            else:
                st.info("No hay datos ENSO disponibles para este an谩lisis.")
        with mensual_datos_tab:
            st.subheader("Datos de Precipitaci贸n Mensual Detallados")
            if not df_monthly_rich.empty:
                df_values = df_monthly_rich.pivot_table(index=Config.DATE_COL, columns=Config.STATION_NAME_COL, values=Config.PRECIPITATION_COL).round(1)
                st.dataframe(df_values, use_container_width=True)
            else:
                st.info("No hay datos mensuales detallados.")

    with sub_tab_comparacion:
        st.subheader("Comparaci贸n de Precipitaci贸n entre Estaciones")
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar.")
        else:
            st.markdown("##### Precipitaci贸n Mensual Promedio")
            
            # MODIFICACIN: Enriquecer el DataFrame para los popups
            df_monthly_avg_rich = df_monthly_rich.groupby([Config.STATION_NAME_COL, Config.MONTH_COL]).agg(
                precip_promedio=(Config.PRECIPITATION_COL, 'mean'),
                precip_max=(Config.PRECIPITATION_COL, 'max'),
                precip_min=(Config.PRECIPITATION_COL, 'min'),
                municipio=(Config.MUNICIPALITY_COL, 'first'),
                altitud=(Config.ALTITUDE_COL, 'first')
            ).reset_index()

            fig_avg_monthly = px.line(
                df_monthly_avg_rich,
                x=Config.MONTH_COL,
                y='precip_promedio',
                color=Config.STATION_NAME_COL,
                labels={Config.MONTH_COL: 'Mes', 'precip_promedio': 'Precipitaci贸n Promedio (mm)'},
                title='Promedio de Precipitaci贸n Mensual por Estaci贸n',
                hover_data={
                    'municipio': True,
                    'altitud': True,
                    'precip_max': ':.0f',
                    'precip_min': ':.0f'
                }
            )
            meses_dict = {'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6, 'Julio': 7, 'Agosto': 8, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12}
            fig_avg_monthly.update_layout(height=500, xaxis=dict(tickmode='array', tickvals=list(meses_dict.values()), ticktext=list(meses_dict.keys())))
            st.plotly_chart(fig_avg_monthly, use_container_width=True)

            st.markdown("##### Distribuci贸n de Precipitaci贸n Anual")
            df_anual_filtered_for_box = df_anual_rich[df_anual_rich[Config.STATION_NAME_COL].isin(stations_for_analysis)]
            fig_box_annual = px.box(
                df_anual_filtered_for_box, x=Config.STATION_NAME_COL, y=Config.PRECIPITATION_COL,
                color=Config.STATION_NAME_COL, points='all', title='Distribuci贸n de la Precipitaci贸n Anual por Estaci贸n',
                labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)'}
            )
            fig_box_annual.update_layout(height=500)
            st.plotly_chart(fig_box_annual, use_container_width=True, key="box_anual_comparacion")

    with sub_tab_distribucion:
        st.subheader("Distribuci贸n de la Precipitaci贸n")
        distribucion_tipo = st.radio("Seleccionar tipo de distribuci贸n:", ("Anual", "Mensual"), horizontal=True)
        plot_type = st.radio("Seleccionar tipo de gr谩fico:", ("Histograma", "Gr谩fico de Violin"), horizontal=True, key="distribucion_plot_type")
        
        hover_info = [Config.MUNICIPALITY_COL, Config.ALTITUDE_COL]
        
        if distribucion_tipo == "Anual":
            if not df_anual_rich.empty:
                if plot_type == "Histograma":
                    fig_hist_anual = px.histogram(
                        df_anual_rich, x=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL,
                        title=f'Distribuci贸n Anual de Precipitaci贸n ({year_min} - {year_max})',
                        labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', 'count': 'Frecuencia'},
                        hover_data=hover_info
                    )
                    fig_hist_anual.update_layout(height=500)
                    st.plotly_chart(fig_hist_anual, use_container_width=True)
                else:
                    fig_violin_anual = px.violin(
                        df_anual_rich, y=Config.PRECIPITATION_COL, x=Config.STATION_NAME_COL, color=Config.STATION_NAME_COL,
                        box=True, points="all", title='Distribuci贸n Anual con Gr谩fico de Violin',
                        labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'},
                        hover_data=hover_info
                    )
                    fig_violin_anual.update_layout(height=500)
                    st.plotly_chart(fig_violin_anual, use_container_width=True)
            else:
                st.warning("No hay datos anuales para mostrar la distribuci贸n.")
        else:
            if not df_monthly_rich.empty:
                if plot_type == "Histograma":
                    fig_hist_mensual = px.histogram(
                        df_monthly_rich, x=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL,
                        title=f'Distribuci贸n Mensual de Precipitaci贸n ({year_min} - {year_max})',
                        labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', 'count': 'Frecuencia'},
                        hover_data=hover_info
                    )
                    fig_hist_mensual.update_layout(height=500)
                    st.plotly_chart(fig_hist_mensual, use_container_width=True)
                else:
                    fig_violin_mensual = px.violin(
                        df_monthly_rich, y=Config.PRECIPITATION_COL, x=Config.MONTH_COL, color=Config.STATION_NAME_COL,
                        box=True, points="all", title='Distribuci贸n Mensual con Gr谩fico de Violin',
                        labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'},
                        hover_data=hover_info
                    )
                    fig_violin_mensual.update_layout(height=500)
                    st.plotly_chart(fig_violin_mensual, use_container_width=True)
            else:
                st.warning("No hay datos mensuales para mostrar el gr谩fico.")

    with sub_tab_acumulada:
        st.subheader("Precipitaci贸n Acumulada Anual")
        if not df_anual_rich.empty:
            # MODIFICACIN: Enriquecer df_acumulada para los popups
            df_acumulada = df_anual_rich.groupby([Config.YEAR_COL, Config.STATION_NAME_COL]).agg(
                precipitation_sum=(Config.PRECIPITATION_COL, 'sum'),
                municipio=(Config.MUNICIPALITY_COL, 'first'),
                altitud=(Config.ALTITUDE_COL, 'first')
            ).reset_index()
            
            fig_acumulada = px.bar(
                df_acumulada, x=Config.YEAR_COL, y='precipitation_sum',
                color=Config.STATION_NAME_COL,
                title=f'Precipitaci贸n Acumulada por A帽o ({year_min} - {year_max})',
                labels={Config.YEAR_COL: 'A帽o', 'precipitation_sum': 'Precipitaci贸n Acumulada (mm)'},
                hover_data=['municipio', 'altitud']
            )
            fig_acumulada.update_layout(barmode='group', height=500)
            st.plotly_chart(fig_acumulada, use_container_width=True)
        else:
            st.info("No hay datos para calcular la precipitaci贸n acumulada.")

    with sub_tab_altitud:
        st.subheader("Relaci贸n entre Altitud y Precipitaci贸n")
        if not df_anual_rich.empty and not df_anual_rich[Config.ALTITUDE_COL].isnull().all():
            df_relacion = df_anual_rich.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].mean().reset_index()
            df_relacion = df_relacion.merge(gdf_filtered[[Config.STATION_NAME_COL, Config.ALTITUDE_COL, Config.MUNICIPALITY_COL]].drop_duplicates(), on=Config.STATION_NAME_COL, how='left')
            fig_relacion = px.scatter(df_relacion, x=Config.ALTITUDE_COL, y=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL, title='Relaci贸n entre Precipitaci贸n Media Anual y Altitud', labels={Config.ALTITUDE_COL: 'Altitud (m)', Config.PRECIPITATION_COL: 'Precipitaci贸n Media Anual (mm)'}, hover_data=[Config.MUNICIPALITY_COL])
            fig_relacion.update_layout(height=500)
            st.plotly_chart(fig_relacion, use_container_width=True)
        else:
            st.info("No hay datos de altitud o precipitaci贸n disponibles para analizar la relaci贸n.")
            
    with sub_tab_regional:
        st.subheader("Serie de Tiempo Promedio Regional (M煤ltiples Estaciones)")
        if not stations_for_analysis:
            st.warning("Seleccione una o m谩s estaciones en el panel lateral para calcular la serie regional.")
        elif df_monthly_rich.empty:
            st.warning("No hay datos mensuales para las estaciones seleccionadas para calcular la serie regional.")
        else:
            with st.spinner("Calculando serie de tiempo regional..."):
                df_regional_avg = df_monthly_rich.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                df_regional_avg.rename(columns={Config.PRECIPITATION_COL: 'Precipitaci贸n Promedio'}, inplace=True)
                show_individual = st.checkbox("Superponer estaciones individuales", value=False) if len(stations_for_analysis) > 1 else False
                fig_regional = go.Figure()
                if show_individual and len(stations_for_analysis) <= 10:
                    for station in stations_for_analysis:
                        df_s = df_monthly_rich[df_monthly_rich[Config.STATION_NAME_COL] == station]
                        fig_regional.add_trace(go.Scatter(x=df_s[Config.DATE_COL], y=df_s[Config.PRECIPITATION_COL], mode='lines', name=station, line=dict(color='rgba(128, 128, 128, 0.5)', width=1.5), showlegend=True))
                elif show_individual:
                    st.info("Demasiadas estaciones seleccionadas para superponer (>10). Mostrando solo el promedio regional.")
                fig_regional.add_trace(go.Scatter(x=df_regional_avg[Config.DATE_COL], y=df_regional_avg['Precipitaci贸n Promedio'], mode='lines', name='Promedio Regional', line=dict(color='#1f77b4', width=3)))
                fig_regional.update_layout(title=f'Serie de Tiempo Promedio Regional ({len(stations_for_analysis)} Estaciones)', xaxis_title="Fecha", yaxis_title="Precipitaci贸n Mensual (mm)", height=550)
                st.plotly_chart(fig_regional, use_container_width=True)
            with st.expander("Ver Datos de la Serie Regional Promedio"):
                df_regional_avg_display = df_regional_avg.rename(columns={'Precipitaci贸n Promedio': 'Precipitaci贸n Promedio Regional (mm)'})
                st.dataframe(df_regional_avg_display.round(1), use_container_width=True)

def display_advanced_maps_tab(gdf_filtered, stations_for_analysis, df_anual_melted, df_monthly_filtered, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("Mapas Avanzados")
    if 'gdf_stations' not in st.session_state or 'year_range' not in st.session_state or 'meses_numeros' not in st.session_state:
        st.warning("Los datos de sesi贸n no est谩n completamente inicializados. Por favor, cargue y procese los datos primero.")
        return
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n."); return

    tab_names = ["Validaci贸n de Interpolaci贸n", "Superficies de Interpolaci贸n", "Visualizaci贸n Temporal", "Gr谩fico de Carrera", "Mapa Animado", "Comparaci贸n de Mapas"]
    validation_tab, kriging_tab, temporal_tab, race_tab, anim_tab, compare_tab = st.tabs(tab_names)

    with gif_tab:
        st.subheader("Distribuci贸n Espacio-Temporal de la Lluvia en Antioquia")
        col_controls, col_gif = st.columns([1, 3])
        with col_controls:
            if st.button("Reiniciar Animaci贸n", key="reset_gif_button"):
                st.rerun()

        with col_gif:
            gif_path = Config.GIF_PATH
            if os.path.exists(gif_path):
                try:
                    with open(gif_path, "rb") as f:
                        gif_bytes = f.read()
                    gif_b64 = base64.b64encode(gif_bytes).decode("utf-8")
                    html_string = f'<img src="data:image/gif;base64,{gif_b64}" width="600" alt="Animaci贸n PPAM">'
                    st.markdown(html_string, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"Ocurri贸 un error al intentar mostrar el GIF: {e}")
            else:
                st.error(f"No se pudo encontrar el archivo GIF en la ruta especificada: {gif_path}")
                
    with temporal_tab:
        st.subheader("Explorador Anual de Precipitaci贸n")
        df_anual_melted_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_melted_non_na.empty:
            all_years_int = sorted(df_anual_melted_non_na[Config.YEAR_COL].unique())
            controls_col, map_col = st.columns([1, 3])
            
            with controls_col:
                st.markdown("##### Opciones de Visualizaci贸n")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "temporal")
                
                selected_year = None
                if len(all_years_int) > 1:
                    selected_year = st.slider('Seleccione un A帽o para Explorar',
                                              min_value=min(all_years_int),
                                              max_value=max(all_years_int),
                                              value=min(all_years_int),
                                              key="temporal_year_slider")
                elif len(all_years_int) == 1:
                    selected_year = all_years_int[0]
                    st.info(f"Mostrando 煤nico a帽o disponible: {selected_year}")

                if selected_year:
                    st.markdown(f"#### Resumen del A帽o: {selected_year}")
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    if not df_year_filtered.empty:
                        num_stations = len(df_year_filtered)
                        st.metric("Estaciones con Datos", num_stations)
                        if num_stations > 1:
                            st.metric("Promedio Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].mean():.0f} mm")
                            st.metric("M谩ximo Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].max():.0f} mm")
                        else:
                            st.metric("Precipitaci贸n Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].iloc[0]:.0f} mm")

            with map_col:
                if selected_year:
                    m_temporal = create_folium_map([4.57, -74.29], 5, selected_base_map_config, selected_overlays_config)
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    
                    if not df_year_filtered.empty:
                        cols_to_merge = [Config.STATION_NAME_COL, Config.MUNICIPALITY_COL, Config.ALTITUDE_COL, 'geometry']
                        df_map_data = pd.merge(df_year_filtered, gdf_filtered[cols_to_merge].drop_duplicates(subset=[Config.STATION_NAME_COL]), on=Config.STATION_NAME_COL, how="inner")
                        
                        if not df_map_data.empty:
                            min_val, max_val = df_anual_melted_non_na[Config.PRECIPITATION_COL].min(), df_anual_melted_non_na[Config.PRECIPITATION_COL].max()
                            if min_val >= max_val: max_val = min_val + 1
                            colormap = cm.LinearColormap(colors=plt.cm.viridis.colors, vmin=min_val, vmax=max_val)
                            
                            for _, row in df_map_data.iterrows():
                                # Use the new specific popup function for this tab
                                popup_object = generate_temporal_map_popup_html(row, df_anual_melted_non_na)
                                folium.CircleMarker(
                                    location=[row['geometry'].y, row['geometry'].x], radius=5,
                                    color=colormap(row[Config.PRECIPITATION_COL]), fill=True,
                                    fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                    tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                                ).add_to(m_temporal)

                            temp_gdf = gpd.GeoDataFrame(df_map_data, geometry='geometry', crs=gdf_filtered.crs)
                            if not temp_gdf.empty:
                                bounds = temp_gdf.total_bounds
                                if np.all(np.isfinite(bounds)):
                                    m_temporal.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])

                            folium.LayerControl().add_to(m_temporal)
                            folium_static(m_temporal, height=700, width=None)
                        else:
                            st.warning("No hay datos de estaciones v谩lidos para el a帽o seleccionado en el mapa.")
                    else:
                        st.info("No hay datos para el a帽o seleccionado.")
                else:
                    st.warning("No hay a帽os con datos v谩lidos en el rango seleccionado.")
        else:
            st.warning("No hay datos anuales para la visualizaci贸n temporal.")

    with race_tab:
        st.subheader("Ranking Anual de Precipitaci贸n por Estaci贸n")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            fig_racing = px.bar(
                df_anual_valid, x=Config.PRECIPITATION_COL, y=Config.STATION_NAME_COL,
                animation_frame=Config.YEAR_COL, orientation='h',
                labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'},
                title="Evoluci贸n de Precipitaci贸n Anual por Estaci贸n"
            )
            fig_racing.update_layout(
                height=max(600, len(stations_for_analysis) * 35),
                yaxis=dict(categoryorder='total ascending')
            )
            st.plotly_chart(fig_racing, use_container_width=True)
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Gr谩fico de Carrera.")

    with anim_tab:
        st.subheader("Mapa Animado de Precipitaci贸n Anual")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            df_anim_merged = pd.merge(
                df_anual_valid,
                gdf_filtered.drop_duplicates(subset=[Config.STATION_NAME_COL]),
                on=Config.STATION_NAME_COL, how="inner"
            )
            if not df_anim_merged.empty:
                fig_mapa_animado = px.scatter_geo(
                    df_anim_merged,
                    lat=Config.LATITUDE_COL, lon=Config.LONGITUDE_COL,
                    color=Config.PRECIPITATION_COL, size=Config.PRECIPITATION_COL,
                    hover_name=Config.STATION_NAME_COL,
                    animation_frame=Config.YEAR_COL,
                    projection='natural earth',
                    title='Precipitaci贸n Anual por Estaci贸n'
                )
                fig_mapa_animado.update_geos(fitbounds="locations", visible=True)
                st.plotly_chart(fig_mapa_animado, use_container_width=True)
            else:
                st.warning("No se pudieron combinar los datos anuales con la informaci贸n geogr谩fica de las estaciones.")
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Mapa Animado.")
            
    with compare_tab:
        st.subheader("Comparaci贸n de Mapas Anuales")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        all_years = sorted(df_anual_valid[Config.YEAR_COL].unique())
        
        if len(all_years) > 1:
            control_col, map_col1, map_col2 = st.columns([1, 2, 2])
            
            with control_col:
                st.markdown("##### Controles de Mapa")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "compare")
                
                min_year, max_year = int(all_years[0]), int(all_years[-1])
                st.markdown("**Mapa 1**")
                year1 = st.selectbox("Seleccione el primer a帽o", options=all_years, index=len(all_years)-1, key="compare_year1")
                st.markdown("**Mapa 2**")
                year2 = st.selectbox("Seleccione el segundo a帽o", options=all_years, index=len(all_years)-2 if len(all_years) > 1 else 0, key="compare_year2")
                
                min_precip, max_precip = int(df_anual_valid[Config.PRECIPITATION_COL].min()), int(df_anual_valid[Config.PRECIPITATION_COL].max())
                if min_precip >= max_precip: max_precip = min_precip + 1
                color_range = st.slider("Rango de Escala de Color (mm)", min_precip, max_precip, (min_precip, max_precip), key="color_compare")
                
                colormap = cm.LinearColormap(colors=plt.cm.viridis.colors, vmin=color_range[0], vmax=color_range[1])

            def create_compare_map(data, year, col, gdf_stations_info, df_anual_full):
                col.markdown(f"**Precipitaci贸n en {year}**")
                m = create_folium_map([6.24, -75.58], 6, selected_base_map_config, selected_overlays_config)
                
                if not data.empty:
                    data_with_geom = pd.merge(data, gdf_stations_info, on=Config.STATION_NAME_COL)
                    gpd_data = gpd.GeoDataFrame(data_with_geom, geometry='geometry', crs=gdf_stations_info.crs)
                    
                    for index, row in gpd_data.iterrows():
                        if pd.notna(row[Config.PRECIPITATION_COL]):
                            popup_object = generate_compare_map_popup_html(row, df_anual_full)
                            folium.CircleMarker(
                                location=[row['geometry'].y, row['geometry'].x], radius=5,
                                color=colormap(row[Config.PRECIPITATION_COL]),
                                fill=True, fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                            ).add_to(m)
                    
                    if not gpd_data.empty:
                        m.fit_bounds(gpd_data.total_bounds.tolist())
                        
                folium.LayerControl().add_to(m)
                with col:
                    folium_static(m, height=450, width=None)
            
            gdf_geometries = gdf_filtered[[
                Config.STATION_NAME_COL, Config.MUNICIPALITY_COL, Config.ALTITUDE_COL, 'geometry'
            ]].drop_duplicates(subset=[Config.STATION_NAME_COL])

            data_year1 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year1]
            data_year2 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year2]
            
            create_compare_map(data_year1, year1, map_col1, gdf_geometries, df_anual_valid)
            create_compare_map(data_year2, year2, map_col2, gdf_geometries, df_anual_valid)
        else:
            st.warning("Se necesitan datos de al menos dos a帽os diferentes para generar la Comparaci贸n de Mapas.")

    with validation_tab:
        st.subheader("Validaci贸n Cruzada Comparativa de M茅todos de Interpolaci贸n")
        df_anual_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        
        if len(stations_for_analysis) < 4:
            st.warning("Se necesitan al menos 4 estaciones para realizar una validaci贸n robusta.")
        else:
            all_years_int = sorted(df_anual_non_na[Config.YEAR_COL].unique())
            selected_year = st.selectbox("Seleccione un a帽o para la validaci贸n:", options=all_years_int, index=len(all_years_int)-1)

            if st.button(f"Ejecutar Validaci贸n para el a帽o {selected_year}"):
                interpolation_methods = ["IDW", "Kriging Ordinario", "Spline (Thin Plate)"]
                if Config.ELEVATION_COL in gdf_filtered.columns:
                    interpolation_methods.append("Kriging con Deriva Externa (KED)")

                results = []
                progress_bar = st.progress(0)
                
                gdf_metadata = pd.DataFrame(gdf_filtered.drop(columns='geometry', errors='ignore'))

                for i, method in enumerate(interpolation_methods):
                    with st.spinner(f"Validando {method}..."):
                        metrics = perform_loocv_for_year(selected_year, method, gdf_metadata, df_anual_non_na)
                        if metrics:
                            results.append({'M茅todo': method, 'RMSE (mm)': metrics['RMSE'], 'MAE (mm)': metrics['MAE']})
                    progress_bar.progress((i + 1) / len(interpolation_methods))
                
                st.success("Validaci贸n completada.")
                results_df = pd.DataFrame(results).sort_values(by='RMSE (mm)')
                
                st.markdown("#### Resultados de la Validaci贸n Cruzada")
                st.dataframe(results_df.style.format('{:.2f}'))

                fig_results = px.bar(results_df, x='M茅todo', y='RMSE (mm)', color='M茅todo',
                                     title=f'Comparaci贸n de Error (RMSE) para el a帽o {selected_year}')
                st.plotly_chart(fig_results, use_container_width=True)

    with kriging_tab:

        st.subheader("Comparaci贸n de Superficies de Interpolaci贸n Anual")
        df_anual_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        
        if not stations_for_analysis:
            st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        elif df_anual_non_na.empty or len(df_anual_non_na[Config.YEAR_COL].unique()) == 0:
            st.warning("No hay suficientes datos anuales para realizar la interpolaci贸n.")
        else:
            min_year, max_year = int(df_anual_non_na[Config.YEAR_COL].min()), int(df_anual_non_na[Config.YEAR_COL].max())
            control_col, map_col1, map_col2 = st.columns([1, 2, 2])
            
            with control_col:
                st.markdown("#### Controles de los Mapas")
                interpolation_methods = ["Kriging Ordinario", "IDW", "Spline (Thin Plate)"]
                if Config.ELEVATION_COL in gdf_filtered.columns:
                    interpolation_methods.insert(1, "Kriging con Deriva Externa (KED)")

                st.markdown("**Mapa 1**")
                year1 = st.slider("Seleccione el a帽o", min_year, max_year, max_year, key="interp_year1")
                method1 = st.selectbox("M茅todo de interpolaci贸n", options=interpolation_methods, key="interp_method1")
                variogram_model1 = None
                if "Kriging" in method1:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model1 = st.selectbox("Modelo de Variograma para Mapa 1", variogram_options, key="var_model_1")

                st.markdown("---")
                st.markdown("**Mapa 2**")
                year2 = st.slider("Seleccione el a帽o", min_year, max_year, max_year - 1 if max_year > min_year else max_year, key="interp_year2")
                method2 = st.selectbox("M茅todo de interpolaci贸n", options=interpolation_methods, index=1, key="interp_method2")
                variogram_model2 = None
                if "Kriging" in method2:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model2 = st.selectbox("Modelo de Variograma para Mapa 2", variogram_options, key="var_model_2")

            # --- CORRECCIN CLAVE ---
            # Preparamos los argumentos simples y "hasheables" para la funci贸n en cach茅
            gdf_bounds = gdf_filtered.total_bounds.tolist() # Una lista simple de n煤meros
            # Un DataFrame de pandas normal (sin geometr铆as)
            gdf_metadata = pd.DataFrame(gdf_filtered.drop(columns='geometry', errors='ignore')) 

            # Llamamos a la funci贸n con los nuevos argumentos simples
            fig1, fig_var1, error1 = create_interpolation_surface(year1, method1, variogram_model1, gdf_bounds, gdf_metadata, df_anual_non_na)
            fig2, fig_var2, error2 = create_interpolation_surface(year2, method2, variogram_model2, gdf_bounds, gdf_metadata, df_anual_non_na)
            
            with map_col1:
                if fig1: st.plotly_chart(fig1, use_container_width=True)
                else: st.info(error1)
            
            with map_col2:
                if fig2: st.plotly_chart(fig2, use_container_width=True)
                else: st.info(error2)

            st.markdown("---")
            st.markdown("##### Variogramas de los Mapas")
            col3, col4 = st.columns(2)
            
            with col3:
                if fig_var1:
                    buf = io.BytesIO()
                    fig_var1.savefig(buf, format="png")
                    st.image(buf)
                    st.download_button(label="Descargar Variograma 1 (PNG)", data=buf.getvalue(), file_name=f"variograma_1_{year1}_{method1}.png", mime="image/png")
                    plt.close(fig_var1)
                else:
                    st.info("El variograma no est谩 disponible para este m茅todo.")
            
            with col4:
                if fig_var2:
                    buf = io.BytesIO()
                    fig_var2.savefig(buf, format="png")
                    st.image(buf)
                    st.download_button(label="Descargar Variograma 2 (PNG)", data=buf.getvalue(), file_name=f"variograma_2_{year2}_{method2}.png", mime="image/png")
                    plt.close(fig_var2)
                else:
                    st.info("El variograma no est谩 disponible para este m茅todo.")

# --- NUEVA FUNCIN PARA MOSTRAR EL ANLISIS DE EVENTOS ---
def display_event_analysis(index_values, index_type):
    """Muestra el panel de control y los resultados del an谩lisis de eventos de sequ铆a/humedad."""
    st.markdown("---")
    st.subheader(f"An谩lisis de Eventos de Sequ铆a y Humedad ({index_type})")
    
    col1, col2 = st.columns(2)
    with col1:
        drought_threshold = st.slider(
            "Umbral de Sequ铆a Moderada", -2.0, 0.0, -1.0, 0.1,
            key=f"drought_thresh_{index_type}",
            help="Un evento de sequ铆a comienza cuando el 铆ndice cae por debajo de este valor."
        )
        extreme_drought_threshold = st.slider(
            "Umbral de Sequ铆a Extrema", -3.0, -1.0, -1.5, 0.1,
            key=f"extreme_drought_thresh_{index_type}",
            help="Eventos que alcanzan un pico por debajo de este valor se consideran extremos."
        )
    with col2:
        wet_threshold = st.slider(
            "Umbral de Per铆odo H煤medo", 0.0, 2.0, 1.0, 0.1,
            key=f"wet_thresh_{index_type}",
            help="Un per铆odo h煤medo comienza cuando el 铆ndice supera este valor."
        )
        extreme_wet_threshold = st.slider(
            "Umbral de Per铆odo H煤medo Extremo", 1.0, 3.0, 1.5, 0.1,
            key=f"extreme_wet_thresh_{index_type}",
            help="Eventos que alcanzan un pico por encima de este valor se consideran extremos."
        )

    # Realizar el an谩lisis
    droughts_df = analyze_events(index_values, drought_threshold, 'drought')
    wet_periods_df = analyze_events(index_values, wet_threshold, 'wet')

    st.markdown("#### Panel Informativo de Eventos")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#####  **Resumen de Sequ铆as**")
        if not droughts_df.empty:
            longest_drought = droughts_df.loc[droughts_df['Duraci贸n (meses)'].idxmax()]
            most_intense = droughts_df.loc[droughts_df['Pico'].idxmin()]
            extreme_count = (droughts_df['Pico'] < extreme_drought_threshold).sum()
            
            st.metric("Sequ铆a m谩s Larga", f"{longest_drought['Duraci贸n (meses)']} meses", f"Inici贸 en {longest_drought['Fecha Inicio'].strftime('%Y-%m')}")
            st.metric("Sequ铆a m谩s Intensa (Pico)", f"{most_intense['Pico']:.2f}", f"Inici贸 en {most_intense['Fecha Inicio'].strftime('%Y-%m')}")
            st.metric(f"N潞 de Eventos de Sequ铆a (<{drought_threshold})", len(droughts_df))
            st.metric(f"N潞 de Eventos Extremos (<{extreme_drought_threshold})", extreme_count)
        else:
            st.info("No se identificaron eventos de sequ铆a con los umbrales seleccionados.")

    with col2:
        st.markdown("##### э **Resumen de Per铆odos H煤medos**")
        # CORRECCIN: Comprobaci贸n robusta de que el DataFrame no est谩 vac铆o
        if not wet_periods_df.empty:
            longest_wet = wet_periods_df.loc[wet_periods_df['Duraci贸n (meses)'].idxmax()]
            most_intense_wet = wet_periods_df.loc[wet_periods_df['Pico'].idxmax()]
            extreme_wet_count = (wet_periods_df['Pico'] > extreme_wet_threshold).sum()

            st.metric("Per铆odo H煤medo m谩s Largo", f"{longest_wet['Duraci贸n (meses)']} meses", f"Inici贸 en {longest_wet['Fecha Inicio'].strftime('%Y-%m')}")
            st.metric("Per铆odo H煤medo m谩s Intenso (Pico)", f"{most_intense_wet['Pico']:.2f}", f"Inici贸 en {most_intense_wet['Fecha Inicio'].strftime('%Y-%m')}")
            st.metric(f"N潞 de Eventos H煤medos (>{wet_threshold})", len(wet_periods_df))
            st.metric(f"N潞 de Eventos Extremos (>{extreme_wet_threshold})", extreme_wet_count)
        else:
            st.info("No se identificaron per铆odos h煤medos con los umbrales seleccionados.")

    st.markdown("---")
    st.subheader("Visualizaci贸n y Datos de Eventos")

    tab_drought, tab_wet = st.tabs(["Eventos de Sequ铆a", "Per铆odos H煤medos"])

    with tab_drought:
        if not droughts_df.empty:
            fig_droughts = px.bar(
                droughts_df, x='Fecha Inicio', y='Duraci贸n (meses)', color='Intensidad',
                title='Duraci贸n e Intensidad de los Eventos de Sequ铆a',
                hover_data=['Magnitud', 'Pico', 'Fecha Fin'],
                color_continuous_scale=px.colors.sequential.Reds_r
            )
            fig_droughts.update_layout(coloraxis_colorbar=dict(title=f"Intensidad<br>({index_type})"))
            st.plotly_chart(fig_droughts, use_container_width=True)
            with st.expander("Ver tabla de datos de eventos de sequ铆a"):
                st.dataframe(droughts_df.style.format({
                    'Fecha Inicio': '{:%Y-%m}', 'Fecha Fin': '{:%Y-%m}',
                    'Magnitud': '{:.2f}', 'Intensidad': '{:.2f}', 'Pico': '{:.2f}'
                }))
        else:
            st.info("No hay datos de sequ铆a para mostrar.")

    with tab_wet:
        if not wet_periods_df.empty:
            fig_wet = px.bar(
                wet_periods_df, x='Fecha Inicio', y='Duraci贸n (meses)', color='Intensidad',
                title='Duraci贸n e Intensidad de los Per铆odos H煤medos',
                hover_data=['Magnitud', 'Pico', 'Fecha Fin'],
                color_continuous_scale=px.colors.sequential.Blues
            )
            fig_wet.update_layout(coloraxis_colorbar=dict(title=f"Intensidad<br>({index_type})"))
            st.plotly_chart(fig_wet, use_container_width=True)
            with st.expander("Ver tabla de datos de per铆odos h煤medos"):
                st.dataframe(wet_periods_df.style.format({
                    'Fecha Inicio': '{:%Y-%m}', 'Fecha Fin': '{:%Y-%m}',
                    'Magnitud': '{:.2f}', 'Intensidad': '{:.2f}', 'Pico': '{:.2f}'
                }))
        else:
            st.info("No hay datos de per铆odos h煤medos para mostrar.")

def display_drought_analysis_tab(df_monthly_filtered, gdf_filtered, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("An谩lisis de Extremos Hidrol贸gicos")
    if 'gdf_stations' not in st.session_state: st.warning("Cargue los datos para continuar."); return
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis: st.warning("Seleccione al menos una estaci贸n."); return
        
    percentile_sub_tab, indices_sub_tab = st.tabs(["An谩lisis por Percentiles", "ndices de Sequ铆a (SPI/SPEI)"])

    with percentile_sub_tab:
        st.subheader("An谩lisis de Eventos Extremos por Percentiles Mensuales")
        station_to_analyze_perc = st.selectbox("Seleccione una estaci贸n:", options=sorted(stations_for_analysis), key="percentile_station_select")
        if station_to_analyze_perc:
            display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc)

    with indices_sub_tab:
        st.subheader("An谩lisis con ndices Estandarizados")
        col1_idx, col2_idx = st.columns([1, 3])
        index_values = pd.Series(dtype=float)
        
        with col1_idx:
            index_type = st.radio("ndice a Calcular:", ("SPI", "SPEI"), key="index_type_radio")
            station_to_analyze_idx = st.selectbox("Estaci贸n para an谩lisis:", options=sorted(stations_for_analysis), key="index_station_select")
            index_window = st.select_slider("Escala de tiempo (meses):", options=[3, 6, 9, 12, 24], value=12, key="index_window_slider")
        
        if station_to_analyze_idx:
            df_station_idx = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_to_analyze_idx].copy().set_index(Config.DATE_COL).sort_index()
            
            with col2_idx:
                with st.spinner(f"Calculando {index_type}-{index_window}..."):
                    if index_type == "SPI":
                        precip_series = df_station_idx[Config.PRECIPITATION_COL]
                        if len(precip_series.dropna()) < index_window * 2:
                            st.warning(f"No hay suficientes datos ({len(precip_series.dropna())} meses) para calcular el SPI-{index_window}.")
                        else:
                            index_values = calculate_spi(precip_series, index_window)
                    
                    elif index_type == "SPEI":
                        if Config.ET_COL not in df_station_idx.columns or df_station_idx[Config.ET_COL].isnull().all():
                            st.error(f"No hay datos de evapotranspiraci贸n ('{Config.ET_COL}') disponibles.")
                        else:
                            precip_series, et_series = df_station_idx[Config.PRECIPITATION_COL], df_station_idx[Config.ET_COL]
                            if len(precip_series.dropna()) < index_window * 2 or len(et_series.dropna()) < index_window * 2:
                                st.warning(f"No hay suficientes datos de precipitaci贸n o ETP para calcular el SPEI-{index_window}.")
                            else:
                                index_values = calculate_spei(precip_series, et_series, index_window)
            
                if not index_values.empty and not index_values.isnull().all():
                    with col2_idx:
                        df_plot = pd.DataFrame({'index_val': index_values}).dropna()
                        conditions = [df_plot['index_val']<=-2.0, (df_plot['index_val']>-2.0)&(df_plot['index_val']<=-1.5), (df_plot['index_val']>-1.5)&(df_plot['index_val']<=-1.0), (df_plot['index_val']>-1.0)&(df_plot['index_val']<1.0), (df_plot['index_val']>=1.0)&(df_plot['index_val']<1.5), (df_plot['index_val']>=1.5)&(df_plot['index_val']<2.0), df_plot['index_val']>=2.0]
                        colors = ['#b2182b', '#ef8a62', '#fddbc7', '#d1e5f0', '#92c5de', '#4393c3', '#2166ac']
                        df_plot['color'] = np.select(conditions, colors, default='grey')
                        fig = go.Figure(go.Bar(x=df_plot.index, y=df_plot['index_val'], marker_color=df_plot['color'], name=index_type))
                        fig.update_layout(title=f"ndice {index_type}-{index_window} para {station_to_analyze_idx}", yaxis_title=f"Valor {index_type}", xaxis_title="Fecha", height=500)
                        st.plotly_chart(fig, use_container_width=True)
                    
                    display_event_analysis(index_values, index_type)

def display_event_analysis(index_values, index_type):
    st.markdown("---"); st.subheader(f"An谩lisis de Eventos de Sequ铆a y Humedad ({index_type})")
    c1, c2 = st.columns(2)
    with c1:
        drought_threshold = st.slider("Umbral de Sequ铆a", -2.0, 0.0, -1.0, 0.1, key=f"drought_thresh_{index_type}", help="Un evento de sequ铆a comienza cuando el 铆ndice cae por debajo de este valor.")
        extreme_drought_threshold = st.slider("Umbral de Sequ铆a Extrema", -3.0, -1.0, -1.5, 0.1, key=f"extreme_drought_thresh_{index_type}", help="Eventos que alcanzan un pico por debajo de este valor se consideran extremos.")
    with c2:
        wet_threshold = st.slider("Umbral H煤medo", 0.0, 2.0, 1.0, 0.1, key=f"wet_thresh_{index_type}", help="Un per铆odo h煤medo comienza cuando el 铆ndice supera este valor.")
        extreme_wet_threshold = st.slider("Umbral H煤medo Extremo", 1.0, 3.0, 1.5, 0.1, key=f"extreme_wet_thresh_{index_type}", help="Eventos que alcanzan un pico por encima de este valor se consideran extremos.")
    
    droughts_df, wet_periods_df = analyze_events(index_values, drought_threshold, 'drought'), analyze_events(index_values, wet_threshold, 'wet')
    
    st.markdown("#### Panel Informativo de Eventos"); c1, c2 = st.columns(2)
    with c1:
        st.markdown("#####  **Resumen de Sequ铆as**")
        if not droughts_df.empty:
            if not droughts_df['Duraci贸n (meses)'].isnull().all():
                longest = droughts_df.loc[droughts_df['Duraci贸n (meses)'].idxmax()]
                st.metric("Sequ铆a m谩s Larga", f"{longest['Duraci贸n (meses)']} meses", f"Inici贸: {longest['Fecha Inicio'].strftime('%Y-%m')}")
            if not droughts_df['Pico'].isnull().all():
                most_intense = droughts_df.loc[droughts_df['Pico'].idxmin()]
                st.metric("Sequ铆a m谩s Intensa (Pico)", f"{most_intense['Pico']:.2f}", f"Inici贸: {most_intense['Fecha Inicio'].strftime('%Y-%m')}")
            extreme_count = (droughts_df['Pico'] < extreme_drought_threshold).sum()
            st.metric(f"N潞 Eventos de Sequ铆a (<{drought_threshold})", len(droughts_df))
            st.metric(f"N潞 Eventos Extremos (<{extreme_drought_threshold})", extreme_count)
        else: st.info("No se identificaron eventos de sequ铆a.")
    with c2:
        st.markdown("##### э **Resumen de Per铆odos H煤medos**")
        if not wet_periods_df.empty:
            if not wet_periods_df['Duraci贸n (meses)'].isnull().all():
                longest = wet_periods_df.loc[wet_periods_df['Duraci贸n (meses)'].idxmax()]
                st.metric("Per铆odo H煤medo m谩s Largo", f"{longest['Duraci贸n (meses)']} meses", f"Inici贸: {longest['Fecha Inicio'].strftime('%Y-%m')}")
            if not wet_periods_df['Pico'].isnull().all():
                most_intense = wet_periods_df.loc[wet_periods_df['Pico'].idxmax()]
                st.metric("Per铆odo H煤medo m谩s Intenso (Pico)", f"{most_intense['Pico']:.2f}", f"Inici贸: {most_intense['Fecha Inicio'].strftime('%Y-%m')}")
            extreme_count = (wet_periods_df['Pico'] > extreme_wet_threshold).sum()
            st.metric(f"N潞 Eventos H煤medos (>{wet_threshold})", len(wet_periods_df))
            st.metric(f"N潞 Eventos Extremos (>{extreme_wet_threshold})", extreme_count)
        else: st.info("No se identificaron per铆odos h煤medos.")
    
    st.markdown("---"); st.subheader("Visualizaci贸n y Datos de Eventos"); tab_drought, tab_wet = st.tabs(["Eventos de Sequ铆a", "Per铆odos H煤medos"])
    with tab_drought:
        if not droughts_df.empty:
            fig = px.bar(droughts_df, x='Fecha Inicio', y='Duraci贸n (meses)', color='Intensidad', title='Duraci贸n e Intensidad de Eventos de Sequ铆a', hover_data=['Magnitud','Pico','Fecha Fin'], color_continuous_scale=px.colors.sequential.Reds_r)
            fig.update_layout(coloraxis_colorbar=dict(title=f"Intensidad<br>({index_type})")); st.plotly_chart(fig, use_container_width=True)
            with st.expander("Ver tabla de datos de sequ铆as"): st.dataframe(droughts_df.style.format({'Fecha Inicio':'{:%Y-%m}','Fecha Fin':'{:%Y-%m}','Magnitud':'{:.2f}','Intensidad':'{:.2f}','Pico':'{:.2f}'}))
        else: st.info("No hay datos de sequ铆a para mostrar.")
    with tab_wet:
        if not wet_periods_df.empty:
            fig = px.bar(wet_periods_df, x='Fecha Inicio', y='Duraci贸n (meses)', color='Intensidad', title='Duraci贸n e Intensidad de Per铆odos H煤medos', hover_data=['Magnitud','Pico','Fecha Fin'], color_continuous_scale=px.colors.sequential.Blues)
            fig.update_layout(coloraxis_colorbar=dict(title=f"Intensidad<br>({index_type})")); st.plotly_chart(fig, use_container_width=True)
            with st.expander("Ver tabla de datos de per铆odos h煤medos"): st.dataframe(wet_periods_df.style.format({'Fecha Inicio':'{:%Y-%m}','Fecha Fin':'{:%Y-%m}','Magnitud':'{:.2f}','Intensidad':'{:.2f}','Pico':'{:.2f}'}))
        else: st.info("No hay datos de per铆odos h煤medos para mostrar.")
                
def display_anomalies_tab(df_long, df_monthly_filtered, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("An谩lisis de Anomal铆as de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
        # --- NUEVOS CONTROLES PARA TIPO DE ANOMALA ---
    st.subheader("Configuraci贸n del An谩lisis")
    analysis_type = st.radio(
        "Calcular anomal铆a con respecto a:",
        ("El promedio del per铆odo seleccionado", "Una Normal Climatol贸gica (per铆odo base fijo)"),
        key="anomaly_type"
    )

    df_anomalias = pd.DataFrame()

    if analysis_type == "Una Normal Climatol贸gica (per铆odo base fijo)":
        years_in_long = sorted(df_long[Config.YEAR_COL].unique())
        default_start = 1991 if 1991 in years_in_long else years_in_long[0]
        default_end = 2020 if 2020 in years_in_long else years_in_long[-1]
        
        c1, c2 = st.columns(2)
        with c1:
            baseline_start = st.selectbox("A帽o de inicio del per铆odo base:", years_in_long, index=years_in_long.index(default_start))
        with c2:
            baseline_end = st.selectbox("A帽o de fin del per铆odo base:", years_in_long, index=years_in_long.index(default_end))

        if baseline_start >= baseline_end:
            st.error("El a帽o de inicio del per铆odo base debe ser anterior al a帽o de fin.")
            return
        
        with st.spinner(f"Calculando anomal铆as vs. normal climatol贸gica ({baseline_start}-{baseline_end})..."):
            df_anomalias = calculate_climatological_anomalies(df_monthly_filtered, df_long, baseline_start, baseline_end)
    else:
        with st.spinner("Calculando anomal铆as vs. promedio del per铆odo..."):
            df_anomalias = calculate_monthly_anomalies(df_monthly_filtered, df_long)

    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an谩lisis de anomal铆as. El DataFrame base no est谩 disponible.")
        return

    df_anomalias = calculate_monthly_anomalies(df_monthly_filtered, df_long)
    if st.session_state.get('exclude_na', False):
        df_anomalias.dropna(subset=['anomalia'], inplace=True)

    if df_anomalias.empty or df_anomalias['anomalia'].isnull().all():
        st.warning("No hay suficientes datos hist贸ricos para calcular y mostrar las anomal铆as con los filtros actuales.")
        return

    anom_graf_tab, anom_fase_tab, anom_extremos_tab = st.tabs(["Gr谩fico de Anomal铆as", "Anomal铆as por Fase ENSO", "Tabla de Eventos Extremos"])

    with anom_graf_tab:
        df_plot = df_anomalias.groupby(Config.DATE_COL).agg(
            anomalia=('anomalia', 'mean'),
            anomalia_oni=(Config.ENSO_ONI_COL, 'first')
        ).reset_index()
        fig = create_anomaly_chart(df_plot)
        st.plotly_chart(fig, use_container_width=True)

    with anom_fase_tab:
        if Config.ENSO_ONI_COL in df_anomalias.columns:
            df_anomalias_enso = df_anomalias.dropna(subset=[Config.ENSO_ONI_COL]).copy()
            conditions = [df_anomalias_enso[Config.ENSO_ONI_COL] >= 0.5, df_anomalias_enso[Config.ENSO_ONI_COL] <= -0.5]
            phases = ['El Ni帽o', 'La Ni帽a']
            df_anomalias_enso['enso_fase'] = np.select(conditions, phases, default='Neutral')
            
            fig_box = px.box(
                df_anomalias_enso, x='enso_fase', y='anomalia', color='enso_fase',
                title="Distribuci贸n de Anomal铆as de Precipitaci贸n por Fase ENSO",
                labels={'anomalia': 'Anomal铆a de Precipitaci贸n (mm)', 'enso_fase': 'Fase ENSO'},
                points='all'
            )
            st.plotly_chart(fig_box, use_container_width=True)
        else:
            st.warning(f"La columna '{Config.ENSO_ONI_COL}' no est谩 disponible para este an谩lisis.")

    with anom_extremos_tab:
        st.subheader("Eventos Mensuales Extremos (Basado en Anomal铆as)")
        df_extremos = df_anomalias.dropna(subset=['anomalia']).copy()
        df_extremos['fecha'] = df_extremos[Config.DATE_COL].dt.strftime('%Y-%m')
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### 10 Meses m谩s Secos")
            secos = df_extremos.nsmallest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL, 'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(secos.rename(columns={
                Config.STATION_NAME_COL: 'Estaci贸n',
                'anomalia': 'Anomal铆a (mm)',
                Config.PRECIPITATION_COL: 'Ppt. (mm)',
                'precip_promedio_mes': 'Ppt. Media (mm)'
            }).round(0), use_container_width=True)
        
        with col2:
            st.markdown("##### 10 Meses m谩s H煤medos")
            humedos = df_extremos.nlargest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL, 'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(humedos.rename(columns={
                Config.STATION_NAME_COL: 'Estaci贸n',
                'anomalia': 'Anomal铆a (mm)',
                Config.PRECIPITATION_COL: 'Ppt. (mm)',
                'precip_promedio_mes': 'Ppt. Media (mm)'
            }).round(0), use_container_width=True)

def display_frequency_analysis_tab(df_anual_melted, stations_for_analysis, **kwargs):
    st.header("An谩lisis de Frecuencia de Precipitaciones Anuales M谩ximas")
    
    st.markdown("""
    Este an谩lisis estima la probabilidad de ocurrencia de un evento de precipitaci贸n de cierta magnitud. 
    Utiliza la distribuci贸n de Gumbel para modelar los valores m谩ximos anuales y calcular los **per铆odos de retorno**.
    """)

    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    station_to_analyze = st.selectbox(
        "Seleccione una estaci贸n para el an谩lisis de frecuencia:",
        options=sorted(stations_for_analysis),
        key="freq_station_select"
    )

    if station_to_analyze:
        station_data = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_to_analyze].copy()
        annual_max_precip = station_data['precipitation'].dropna()

        if len(annual_max_precip) < 10:
            st.warning("Se recomiendan al menos 10 a帽os de datos para un an谩lisis de frecuencia confiable.")
        else:
            with st.spinner("Calculando per铆odos de retorno..."):
                # Ajustar datos a la distribuci贸n Gumbel
                params = stats.gumbel_r.fit(annual_max_precip)
                
                # Calcular valores para los per铆odos de retorno
                return_periods = np.array([2, 5, 10, 25, 50, 100, 200, 500])
                non_exceed_prob = 1 - 1 / return_periods
                precip_values = stats.gumbel_r.ppf(non_exceed_prob, *params)

                results_df = pd.DataFrame({
                    "Per铆odo de Retorno (a帽os)": return_periods,
                    "Precipitaci贸n Anual Esperada (mm)": precip_values
                })
                
                st.subheader(f"Resultados para la estaci贸n: {station_to_analyze}")
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.markdown("#### Tabla de Resultados")
                    st.dataframe(results_df.style.format({"Precipitaci贸n Anual Esperada (mm)": "{:.1f}"}))

                with col2:
                    st.markdown("#### Curva de Frecuencia")
                    fig = go.Figure()
                    # Datos observados
                    fig.add_trace(go.Scatter(
                        x=station_data['a帽o'],
                        y=annual_max_precip,
                        mode='markers',
                        name='M谩ximos Anuales Observados'
                    ))
                    # Curva ajustada
                    x_plot = np.linspace(annual_max_precip.min(), precip_values[-1] * 1.1, 100)
                    y_plot_prob = stats.gumbel_r.cdf(x_plot, *params)
                    y_plot_return_period = 1 / (1 - y_plot_prob)
                    
                    fig.add_trace(go.Scatter(
                        x=y_plot_return_period,
                        y=x_plot,
                        mode='lines',
                        name='Curva de Gumbel Ajustada',
                        line=dict(color='red')
                    ))
                    
                    fig.update_layout(
                        title="Curva de Per铆odos de Retorno",
                        xaxis_title="Per铆odo de Retorno (a帽os)",
                        yaxis_title="Precipitaci贸n Anual (mm)",
                        xaxis_type="log"
                    )
                    st.plotly_chart(fig, use_container_width=True)

def display_stats_tab(df_long, df_anual_melted, df_monthly_filtered, stations_for_analysis, gdf_filtered, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("Estad铆sticas de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis: st.warning("Por favor, seleccione al menos una estaci贸n."); return

    matriz_tab, resumen_mensual_tab, series_tab, sintesis_tab = st.tabs(["Matriz de Disponibilidad", "Resumen Mensual", "Datos Series Pptn", "S铆ntesis General"])
    
    with series_tab:
        st.subheader("Series de Precipitaci贸n Anual por Estaci贸n (mm)")
        if not df_anual_melted.empty:
            ppt_series_df = df_anual_melted.pivot_table(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values=Config.PRECIPITATION_COL)
            st.dataframe(ppt_series_df.style.format("{:.0f}", na_rep="-").background_gradient(cmap='viridis', axis=1))
        else:
            st.info("No hay datos anuales para mostrar en la tabla.")
  
    with matriz_tab:
        st.subheader("Matriz de Disponibilidad de Datos Anual")
        df_base_raw = st.session_state.get('df_monthly_processed', pd.DataFrame())
        
        if df_base_raw.empty:
            st.warning("Los datos procesados no est谩n disponibles en la sesi贸n.")
            return
            
        df_base_filtered = df_base_raw[df_base_raw[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()
        
        if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
            view_mode = st.radio(
                "Seleccione la vista de la matriz:",
                ("Porcentaje de Datos Originales", "Porcentaje de Datos Totales (Original + Completado)", "Porcentaje de Datos Completados (Interpolados)"),
                horizontal=True
            )
            if view_mode == "Porcentaje de Datos Completados (Interpolados)":
                df_counts = df_base_filtered[df_base_filtered[Config.ORIGIN_COL] == 'Completado'].groupby([Config.STATION_NAME_COL, Config.YEAR_COL]).size().reset_index(name='count_completed')
                df_counts['porc_value'] = (df_counts['count_completed'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Reds"
                title_text = "Porcentaje de Datos Completados (Interpolados)"
            elif view_mode == "Porcentaje de Datos Totales (Original + Completado)":
                df_counts = df_base_filtered.groupby([Config.STATION_NAME_COL, Config.YEAR_COL]).size().reset_index(name='count_total')
                df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Blues"
                title_text = "Disponibilidad de Datos Totales (Original + Completado)"
            else: # Porcentaje de Datos Originales
                df_original_filtered = df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                df_counts = df_original_filtered.groupby([Config.STATION_NAME_COL, Config.YEAR_COL]).size().reset_index(name='count_original')
                df_counts['porc_value'] = (df_counts['count_original'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Greens"
                title_text = "Disponibilidad de Datos Originales"
        else: # Usar datos originales (Modo por defecto)
            df_base_filtered = df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()
            df_counts = df_base_filtered.groupby([Config.STATION_NAME_COL, Config.YEAR_COL]).size().reset_index(name='count_total')
            df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
            heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
            color_scale = "Greens"
            title_text = "Disponibilidad de Datos Originales"
            
        if not heatmap_df.empty:
            avg_availability = heatmap_df.stack().mean()
            logo_col, metric_col = st.columns([1, 5])
            with logo_col:
                if os.path.exists(Config.LOGO_PATH):
                    try:
                        with open(Config.LOGO_PATH, "rb") as f:
                            logo_bytes = f.read()
                        st.image(logo_bytes, width=50)
                    except Exception:
                        pass
            with metric_col:
                st.metric(label=f"Disponibilidad Promedio Anual ({title_text})", value=f"{avg_availability:.1f}%")

            styled_df = heatmap_df.style.background_gradient(cmap=color_scale, axis=None, vmin=0, vmax=100).format("{:.0f}%", na_rep="-").set_table_styles([
                {'selector': 'th', 'props': [('background-color', '#333'), ('color', 'white'), ('font-size', '14px')]},
                {'selector': 'td', 'props': [('text-align', 'center')]}
            ])
            st.dataframe(styled_df)
        else:
            st.info("No hay datos para mostrar en la matriz con la selecci贸n actual.")

    with resumen_mensual_tab:
        st.subheader("Resumen de Estad铆sticas Mensuales por Estaci贸n")
        if not df_monthly_filtered.empty:
            summary_data = []
            for station_name, group in df_monthly_filtered.groupby(Config.STATION_NAME_COL):
                max_row = group.loc[group[Config.PRECIPITATION_COL].idxmax()]
                min_row = group.loc[group[Config.PRECIPITATION_COL].idxmin()]
                summary_data.append({
                    "Estaci贸n": station_name,
                    "Ppt. M谩xima Mensual (mm)": max_row[Config.PRECIPITATION_COL],
                    "Fecha M谩xima": max_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Ppt. M铆nima Mensual (mm)": min_row[Config.PRECIPITATION_COL],
                    "Fecha M铆nima": min_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Promedio Mensual (mm)": group[Config.PRECIPITATION_COL].mean()
                })
            summary_df = pd.DataFrame(summary_data)
            st.dataframe(summary_df.round(0), use_container_width=True)
        else:
            st.info("No hay datos para mostrar el resumen mensual.")

    with sintesis_tab:
        st.subheader("S铆ntesis General de Precipitaci贸n")
        if not df_monthly_filtered.empty and not df_anual_melted.empty:
            df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
            df_monthly_valid = df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL])
            
            if not df_anual_valid.empty and not df_monthly_valid.empty and not gdf_filtered.empty:
                #--- A. EXTREMOS DE PRECIPITACIN
                max_monthly_row = df_monthly_valid.loc[df_monthly_valid[Config.PRECIPITATION_COL].idxmax()]
                min_monthly_row = df_monthly_valid.loc[df_monthly_valid[Config.PRECIPITATION_COL].idxmin()]
                max_annual_row = df_anual_valid.loc[df_anual_valid[Config.PRECIPITATION_COL].idxmax()]
                min_annual_row = df_anual_valid.loc[df_anual_valid[Config.PRECIPITATION_COL].idxmin()]

                #--- B. PROMEDIOS REGIONALES/CLIMATOLGICOS ---
                df_yearly_avg = df_anual_valid.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                year_max_avg = df_yearly_avg.loc[df_yearly_avg[Config.PRECIPITATION_COL].idxmax()]
                year_min_avg = df_yearly_avg.loc[df_yearly_avg[Config.PRECIPITATION_COL].idxmin()]
                
                df_monthly_avg = df_monthly_valid.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                month_max_avg = df_monthly_avg.loc[df_monthly_avg[Config.PRECIPITATION_COL].idxmax()][Config.MONTH_COL]
                month_min_avg = df_monthly_avg.loc[df_monthly_avg[Config.PRECIPITATION_COL].idxmin()][Config.MONTH_COL]

                #--- C. EXTREMOS DE ALTITUD
                df_stations_valid = gdf_filtered.dropna(subset=[Config.ALTITUDE_COL])
                station_max_alt = None
                station_min_alt = None
                if not df_stations_valid.empty:
                    station_max_alt = df_stations_valid.loc[df_stations_valid[Config.ALTITUDE_COL].astype(float).idxmax()]
                    station_min_alt = df_stations_valid.loc[df_stations_valid[Config.ALTITUDE_COL].astype(float).idxmin()]

                #--- D. CLCULO DE TENDENCIAS (SEN'S SLOPE)
                trend_results = []
                for station in stations_for_analysis:
                    station_data = df_anual_valid[df_anual_valid[Config.STATION_NAME_COL] == station].copy()
                    if len(station_data) >= 4:
                        mk_result_table = mk.original_test(station_data[Config.PRECIPITATION_COL])
                        trend_results.append({
                            Config.STATION_NAME_COL: station,
                            'slope_sen': mk_result_table.slope,
                            'p_value': mk_result_table.p
                        })
                
                df_trends = pd.DataFrame(trend_results)
                max_pos_trend_row = None
                min_neg_trend_row = None
                if not df_trends.empty:
                    df_pos_trends = df_trends[df_trends['slope_sen'] > 0]
                    df_neg_trends = df_trends[df_trends['slope_sen'] < 0]
                    if not df_pos_trends.empty:
                        max_pos_trend_row = df_pos_trends.loc[df_pos_trends['slope_sen'].idxmax()]
                    if not df_neg_trends.empty:
                        min_neg_trend_row = df_neg_trends.loc[df_neg_trends['slope_sen'].idxmin()]

                meses_map = {1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril', 5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto', 9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'}

                #--- DISPLAY DE RESULTADOS
                st.markdown("#### 1. Extremos de Precipitaci贸n")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("M谩xima Ppt. Anual", f"{max_annual_row[Config.PRECIPITATION_COL]:.0f} mm", f"{max_annual_row[Config.STATION_NAME_COL]} ({int(max_annual_row[Config.YEAR_COL])})")
                with col2:
                    st.metric("M铆nima Ppt. Anual", f"{min_annual_row[Config.PRECIPITATION_COL]:.0f} mm", f"{min_annual_row[Config.STATION_NAME_COL]} ({int(min_annual_row[Config.YEAR_COL])})")
                with col3:
                    st.metric("M谩xima Ppt. Mensual", f"{max_monthly_row[Config.PRECIPITATION_COL]:.0f} mm", f"{max_monthly_row[Config.STATION_NAME_COL]} ({meses_map.get(max_monthly_row[Config.MONTH_COL])} {max_monthly_row[Config.DATE_COL].year})")
                with col4:
                    st.metric("M铆nima Ppt. Mensual", f"{min_monthly_row[Config.PRECIPITATION_COL]:.0f} mm", f"{min_monthly_row[Config.STATION_NAME_COL]} ({meses_map.get(min_monthly_row[Config.MONTH_COL])} {min_monthly_row[Config.DATE_COL].year})")

                st.markdown("#### 2. Promedios Hist贸ricos y Climatol贸gicos")
                col5, col6, col7 = st.columns(3)
                with col5:
                    st.metric("A帽o m谩s Lluvioso (Promedio Regional)", f"{year_max_avg[Config.PRECIPITATION_COL]:.0f} mm", f"A帽o: {int(year_max_avg[Config.YEAR_COL])}")
                with col6:
                    st.metric("A帽o menos Lluvioso (Promedio Regional)", f"{year_min_avg[Config.PRECIPITATION_COL]:.0f} mm", f"A帽o: {int(year_min_avg[Config.YEAR_COL])}")
                with col7:
                    st.metric("Mes Climatol贸gico m谩s Lluvioso", f"{df_monthly_avg.loc[df_monthly_avg[Config.MONTH_COL] == month_max_avg, Config.PRECIPITATION_COL].iloc[0]:.0f} mm", f"{meses_map.get(month_max_avg)} (M铆n: {meses_map.get(month_min_avg)})")
                
                st.markdown("#### 3. Geograf铆a y Tendencias")
                col8, col9, col10, col11 = st.columns(4)
                with col8:
                    if station_max_alt is not None:
                        st.metric("Estaci贸n a Mayor Altitud", f"{float(station_max_alt[Config.ALTITUDE_COL]):.0f} m", f"{station_max_alt[Config.STATION_NAME_COL]}")
                    else:
                        st.info("No hay datos de altitud.")
                with col9:
                    if station_min_alt is not None:
                        st.metric("Estaci贸n a Menor Altitud", f"{float(station_min_alt[Config.ALTITUDE_COL]):.0f} m", f"{station_min_alt[Config.STATION_NAME_COL]}")
                    else:
                        st.info("No hay datos de altitud.")
                with col10:
                    if max_pos_trend_row is not None:
                        st.metric("Mayor Tendencia Positiva", f"+{max_pos_trend_row['slope_sen']:.2f} mm/a帽o", f"{max_pos_trend_row[Config.STATION_NAME_COL]} (p={max_pos_trend_row['p_value']:.3f})")
                    else:
                        st.info("No hay tendencias positivas para mostrar.")
                with col11:
                    if min_neg_trend_row is not None:
                        st.metric("Mayor Tendencia Negativa", f"{min_neg_trend_row['slope_sen']:.2f} mm/a帽o", f"{min_neg_trend_row[Config.STATION_NAME_COL]} (p={min_neg_trend_row['p_value']:.3f})")
                    else:
                        st.info("No hay tendencias negativas para mostrar.")
            else:
                st.info("No hay datos anuales, mensuales o geogr谩ficos v谩lidos para mostrar la s铆ntesis.")
        else:
            st.info("No hay datos para mostrar la s铆ntesis general.")

def display_correlation_tab(df_monthly_filtered, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("An谩lisis de Correlaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    st.markdown("Esta secci贸n cuantifica la relaci贸n lineal entre la precipitaci贸n y diferentes variables utilizando el coeficiente de correlaci贸n de Pearson.")
    
    # AADIMOS UNA NUEVA PESTAA A LA LISTA
    tab_names = ["Correlaci贸n con ENSO (ONI)", "Matriz entre Estaciones", "Comparaci贸n 1 a 1", "Correlaci贸n con Otros ndices"]
    enso_corr_tab, matrix_corr_tab, station_corr_tab, indices_climaticos_tab = st.tabs(tab_names)
    
    with enso_corr_tab:
        if Config.ENSO_ONI_COL not in df_monthly_filtered.columns or df_monthly_filtered[Config.ENSO_ONI_COL].isnull().all():
            st.warning(f"No se puede realizar el an谩lisis de correlaci贸n con ENSO. La columna '{Config.ENSO_ONI_COL}' no fue encontrada o no tiene datos en el per铆odo seleccionado.")
            return

        st.subheader("Configuraci贸n del An谩lisis de Correlaci贸n con ENSO")
        lag_months = st.slider(
            "Seleccionar desfase temporal (meses)",
            min_value=0, max_value=12, value=0,
            help="Analiza la correlaci贸n de la precipitaci贸n con el ENSO de 'x' meses atr谩s. Un desfase de 3 significa correlacionar la lluvia de hoy con el ENSO de hace 3 meses."
        )
        
        df_corr_analysis = df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL, Config.ENSO_ONI_COL])
        if df_corr_analysis.empty:
            st.warning("No hay datos coincidentes entre la precipitaci贸n y el ENSO para la selecci贸n actual.")
            return

        analysis_level = st.radio("Nivel de An谩lisis de Correlaci贸n con ENSO", ["Promedio de la selecci贸n", "Por Estaci贸n Individual"], horizontal=True, key="enso_corr_level")
        
        df_plot_corr = pd.DataFrame()
        title_text = ""
        
        if analysis_level == "Por Estaci贸n Individual":
            station_to_corr = st.selectbox("Seleccione Estaci贸n:", options=sorted(df_corr_analysis[Config.STATION_NAME_COL].unique()), key="enso_corr_station")
            if station_to_corr:
                df_plot_corr = df_corr_analysis[df_corr_analysis[Config.STATION_NAME_COL] == station_to_corr].copy()
                title_text = f"Correlaci贸n para la estaci贸n: {station_to_corr}"
            else:
                return # Si no se selecciona estaci贸n
        else:
            df_plot_corr = df_corr_analysis.groupby(Config.DATE_COL).agg(
                precipitation=(Config.PRECIPITATION_COL, 'mean'),
                anomalia_oni=(Config.ENSO_ONI_COL, 'first')
            ).reset_index()
            title_text = "Correlaci贸n para el promedio de las estaciones seleccionadas"

        if not df_plot_corr.empty and len(df_plot_corr) > 2:
            if lag_months > 0:
                df_plot_corr['anomalia_oni_shifted'] = df_plot_corr['anomalia_oni'].shift(lag_months)
                df_plot_corr.dropna(subset=['anomalia_oni_shifted'], inplace=True)
                oni_column_to_use = 'anomalia_oni_shifted'
                lag_text = f" (con desfase de {lag_months} meses)"
            else:
                oni_column_to_use = 'anomalia_oni'
                lag_text = ""

            corr, p_value = stats.pearsonr(df_plot_corr[oni_column_to_use], df_plot_corr['precipitation'])
            
            st.subheader(title_text + lag_text)
            col1, col2 = st.columns(2)
            col1.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
            col2.metric("Significancia (valor p)", f"{p_value:.4f}")
            
            if p_value < 0.05:
                st.success("La correlaci贸n es estad铆sticamente significativa.")
            else:
                st.warning("La correlaci贸n no es estad铆sticamente significativa.")

            fig_corr = px.scatter(
                df_plot_corr, x=oni_column_to_use, y='precipitation', trendline='ols',
                title=f"Dispersi贸n: Precipitaci贸n vs. Anomal铆a ONI{lag_text}",
                labels={oni_column_to_use: f'Anomal铆a ONI (掳C) [desfase {lag_months}m]', 'precipitation': 'Precipitaci贸n Mensual (mm)'}
            )
            st.plotly_chart(fig_corr, use_container_width=True)
        else:
            st.warning("No hay suficientes datos superpuestos para calcular la correlaci贸n.")

    with matrix_corr_tab:
        st.subheader("Matriz de Correlaci贸n de Precipitaci贸n entre Estaciones")
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para generar la matriz de correlaci贸n.")
        else:
            with st.spinner("Calculando matriz de correlaci贸n..."):
                df_pivot = df_monthly_filtered.pivot_table(
                    index=Config.DATE_COL, 
                    columns=Config.STATION_NAME_COL, 
                    values=Config.PRECIPITATION_COL
                )
                corr_matrix = df_pivot.corr()
                
                fig_matrix = px.imshow(
                    corr_matrix,
                    text_auto=True,
                    aspect="auto",
                    color_continuous_scale='RdBu_r',
                    title="Mapa de Calor de Correlaciones de Precipitaci贸n Mensual"
                )
                fig_matrix.update_layout(height=max(400, len(stations_for_analysis) * 25))
                st.plotly_chart(fig_matrix, use_container_width=True)

    with station_corr_tab:
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar la correlaci贸n entre ellas.")
        else:
            st.subheader("Correlaci贸n de Precipitaci贸n entre dos Estaciones")
            station_options = sorted(stations_for_analysis)
            col1, col2 = st.columns(2)
            station1_name = col1.selectbox("Estaci贸n 1:", options=station_options, key="corr_station_1")
            station2_name = col2.selectbox("Estaci贸n 2:", options=station_options, index=1 if len(station_options) > 1 else 0, key="corr_station_2")
            
            if station1_name and station2_name and station1_name != station2_name:
                df_station1 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station1_name][[Config.DATE_COL, Config.PRECIPITATION_COL]]
                df_station2 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station2_name][[Config.DATE_COL, Config.PRECIPITATION_COL]]
                
                df_merged = pd.merge(df_station1, df_station2, on=Config.DATE_COL, suffixes=('_1', '_2')).dropna()
                df_merged.rename(columns={f'{Config.PRECIPITATION_COL}_1': station1_name, f'{Config.PRECIPITATION_COL}_2': station2_name}, inplace=True)
                
                if not df_merged.empty and len(df_merged) > 2:
                    corr, p_value = stats.pearsonr(df_merged[station1_name], df_merged[station2_name])
                    st.markdown(f"#### Resultados de la correlaci贸n ({station1_name} vs. {station2_name})")
                    st.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
                    
                    if p_value < 0.05:
                        st.success(f"La correlaci贸n es estad铆sticamente significativa (p={p_value:.4f}).")
                    else:
                        st.warning(f"La correlaci贸n no es estad铆sticamente significativa (p={p_value:.4f}).")
                    
                    slope, intercept, _, _, _ = stats.linregress(df_merged[station1_name], df_merged[station2_name])
                    st.info(f"Ecuaci贸n de regresi贸n: y = {slope:.2f}x + {intercept:.2f}")

                    fig_scatter = px.scatter(
                        df_merged, x=station1_name, y=station2_name, trendline='ols',
                        title=f'Dispersi贸n de Precipitaci贸n: {station1_name} vs. {station2_name}',
                        labels={station1_name: f'Precipitaci贸n en {station1_name} (mm)', station2_name: f'Precipitaci贸n en {station2_name} (mm)'}
                    )
                    st.plotly_chart(fig_scatter, use_container_width=True)
                else:
                    st.warning("No hay suficientes datos superpuestos para calcular la correlaci贸n para las estaciones seleccionadas.")

    with indices_climaticos_tab:
        st.subheader("An谩lisis de Correlaci贸n con ndices Clim谩ticos (SOI, IOD)")
        available_indices = []
        if Config.SOI_COL in df_monthly_filtered.columns and not df_monthly_filtered[Config.SOI_COL].isnull().all():
            available_indices.append("SOI")
        if Config.IOD_COL in df_monthly_filtered.columns and not df_monthly_filtered[Config.IOD_COL].isnull().all():
            available_indices.append("IOD")
            
        if not available_indices:
            st.warning("No se encontraron columnas para los 铆ndices clim谩ticos (SOI o IOD) en el archivo principal o no hay datos en el per铆odo seleccionado.")
        else:
            col1_corr, col2_corr = st.columns(2)
            selected_index = col1_corr.selectbox("Seleccione un 铆ndice clim谩tico:", available_indices)
            selected_station_corr = col2_corr.selectbox("Seleccione una estaci贸n:", options=sorted(stations_for_analysis), key="station_for_index_corr")
            
            if selected_index and selected_station_corr:
                index_col_map = {"SOI": Config.SOI_COL, "IOD": Config.IOD_COL}
                index_col_name = index_col_map.get(selected_index)
                
                df_merged_indices = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == selected_station_corr].copy()
                
                if index_col_name in df_merged_indices.columns:
                    df_merged_indices.dropna(subset=[Config.PRECIPITATION_COL, index_col_name], inplace=True)
                else:
                    st.error(f"La columna para el 铆ndice '{selected_index}' no se encontr贸 en los datos de la estaci贸n.")
                    return
                
                if not df_merged_indices.empty and len(df_merged_indices) > 2:
                    corr, p_value = stats.pearsonr(df_merged_indices[index_col_name], df_merged_indices[Config.PRECIPITATION_COL])
                    st.markdown(f"#### Resultados de la correlaci贸n ({selected_index} vs. Precipitaci贸n de {selected_station_corr})")
                    st.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
                    
                    if p_value < 0.05:
                        st.success("La correlaci贸n es estad铆sticamente significativa.")
                    else:
                        st.warning("La correlaci贸n no es estad铆sticamente significativa.")
                        
                    fig_scatter_indices = px.scatter(
                        df_merged_indices, x=index_col_name, y=Config.PRECIPITATION_COL,
                        trendline='ols',
                        title=f'Dispersi贸n: {selected_index} vs. Precipitaci贸n de {selected_station_corr}',
                        labels={index_col_name: f'Valor del 铆ndice {selected_index}', Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)'}
                    )
                    st.plotly_chart(fig_scatter_indices, use_container_width=True)
                else:
                    st.warning("No hay suficientes datos superpuestos entre la estaci贸n y el 铆ndice para calcular la correlaci贸n.")

def display_enso_tab(df_enso, df_monthly_filtered, gdf_filtered, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("An谩lisis de Precipitaci贸n y el Fen贸meno ENSO")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    if df_enso is None or df_enso.empty:
        st.warning("No se encontraron datos del fen贸meno ENSO en el archivo de precipitaci贸n cargado.")
        return

    enso_series_tab, enso_anim_tab = st.tabs(["Series de Tiempo ENSO", "Mapa Interactivo ENSO"])

    with enso_series_tab:
        enso_vars_available = {
            Config.ENSO_ONI_COL: 'Anomal铆a ONI',
            'temp_sst': 'Temp. Superficial del Mar (SST)',
            'temp_media': 'Temp. Media'
        }
        available_tabs = [name for var, name in enso_vars_available.items() if var in df_enso.columns]
        
        if not available_tabs:
            st.warning("No hay variables ENSO disponibles en el archivo de datos para visualizar.")
        else:
            enso_variable_tabs = st.tabs(available_tabs)
            for i, var_name in enumerate(available_tabs):
                with enso_variable_tabs[i]:
                    var_code = [code for code, name in enso_vars_available.items() if name == var_name][0]
                    enso_filtered = df_enso
                    if not enso_filtered.empty and var_code in enso_filtered.columns and not enso_filtered[var_code].isnull().all():
                        fig_enso_series = px.line(enso_filtered, x=Config.DATE_COL, y=var_code, title=f"Serie de Tiempo para {var_name}")
                        st.plotly_chart(fig_enso_series, use_container_width=True)
                    else:
                        st.warning(f"No hay datos disponibles para '{var_code}' en el per铆odo seleccionado.")

    with enso_anim_tab:
        st.subheader("Explorador Mensual del Fen贸meno ENSO")
        if gdf_filtered.empty or Config.ENSO_ONI_COL not in df_enso.columns:
            st.warning("Datos insuficientes para generar esta visualizaci贸n. Se requiere informaci贸n de estaciones y la columna 'anomalia_oni'.")
            return
            
        controls_col, map_col = st.columns([1, 3])
        
        enso_anim_data = df_enso[[Config.DATE_COL, Config.ENSO_ONI_COL]].copy().dropna(subset=[Config.ENSO_ONI_COL])
        conditions = [enso_anim_data[Config.ENSO_ONI_COL] >= 0.5, enso_anim_data[Config.ENSO_ONI_COL] <= -0.5]
        phases = ['El Ni帽o', 'La Ni帽a']
        enso_anim_data['fase'] = np.select(conditions, phases, default='Neutral')

        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
        
        enso_anim_data_filtered = enso_anim_data[
            (enso_anim_data[Config.DATE_COL].dt.year >= year_min) &
            (enso_anim_data[Config.DATE_COL].dt.year <= year_max)
        ]
        
        selected_date = None
        with controls_col:
            st.markdown("##### Controles de Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st, "enso_anim")
            st.markdown("##### Selecci贸n de Fecha")
            
            available_dates = sorted(enso_anim_data_filtered[Config.DATE_COL].unique())
            if available_dates:
                selected_date = st.select_slider("Seleccione una fecha (A帽o-Mes)",
                                                 options=available_dates,
                                                 format_func=lambda date: pd.to_datetime(date).strftime('%Y-%m'))
                
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] == selected_date]
                if not phase_info.empty:
                    current_phase = phase_info['fase'].iloc[0]
                    current_oni = phase_info[Config.ENSO_ONI_COL].iloc[0]
                    st.metric(f"Fase ENSO en {pd.to_datetime(selected_date).strftime('%Y-%m')}", current_phase, f"Anomal铆a ONI: {current_oni:.2f}掳C")
                else:
                    st.warning("No hay datos de ENSO para el per铆odo seleccionado.")
            else:
                st.warning("No hay fechas con datos ENSO en el rango seleccionado.")

        with map_col:
            if selected_date:
                m_enso = create_folium_map([4.57, -74.29], 5, selected_base_map_config, selected_overlays_config)
                phase_color_map = {'El Ni帽o': 'red', 'La Ni帽a': 'blue', 'Neutral': 'gray'}
                
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] == selected_date]
                current_phase_str = phase_info['fase'].iloc[0] if not phase_info.empty else "N/A"
                marker_color = phase_color_map.get(current_phase_str, 'black')
                
                for _, station in gdf_filtered.iterrows():
                    folium.Marker(
                        location=[station['geometry'].y, station['geometry'].x],
                        tooltip=f"{station[Config.STATION_NAME_COL]}<br>Fase: {current_phase_str}",
                        icon=folium.Icon(color=marker_color, icon='cloud')
                    ).add_to(m_enso)
                
                if not gdf_filtered.empty:
                    bounds = gdf_filtered.total_bounds
                    if np.all(np.isfinite(bounds)):
                        m_enso.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])

                folium.LayerControl().add_to(m_enso)
                folium_static(m_enso, height=700, width=None)
            else:
                st.info("Seleccione una fecha para visualizar el mapa.")

def display_trends_and_forecast_tab(df_anual_melted, df_monthly_to_process, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("An谩lisis de Tendencias y Pron贸sticos")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )

    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    tab_names = [
        "An谩lisis Lineal", "Tendencia Mann-Kendall", "Tabla Comparativa",
        "Descomposici贸n de Series", "Autocorrelaci贸n (ACF/PACF)",
        "Pron贸stico SARIMA", "Pron贸stico Prophet", "SARIMA vs Prophet"
    ]
    
    tendencia_individual_tab, mann_kendall_tab, tendencia_tabla_tab, descomposicion_tab, \
    autocorrelacion_tab, pronostico_sarima_tab, pronostico_prophet_tab, \
    compare_forecast_tab = st.tabs(tab_names)

    with tendencia_individual_tab:
        st.subheader("Tendencia de Precipitaci贸n Anual (Regresi贸n Lineal)")
        analysis_type = st.radio("Tipo de An谩lisis de Tendencia:", ["Promedio de la selecci贸n", "Estaci贸n individual"], horizontal=True, key="linear_trend_type")
        
        df_to_analyze = None
        title_for_download = "promedio"
        
        if analysis_type == "Promedio de la selecci贸n":
            df_to_analyze = df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze = st.selectbox("Seleccione una estaci贸n para analizar:", options=stations_for_analysis, key="tendencia_station_select")
            if station_to_analyze:
                df_to_analyze = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_to_analyze]
                title_for_download = station_to_analyze.replace(" ", "_")

        if df_to_analyze is not None and len(df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])) > 2:
            df_to_analyze['a帽o_num'] = pd.to_numeric(df_to_analyze[Config.YEAR_COL])
            df_clean = df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])
            slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['a帽o_num'], df_clean[Config.PRECIPITATION_COL])
            
            tendencia_texto = "aumentando" if slope > 0 else "disminuyendo"
            significancia_texto = "**estad铆sticamente significativa**" if p_value < 0.05 else "no es **estad铆sticamente significativa**"
            st.markdown(f"La tendencia de la precipitaci贸n es de **{slope:.2f} mm/a帽o** (es decir, est谩 {tendencia_texto}). Con un valor p de **{p_value:.3f}**, esta tendencia {significancia_texto}.")
            
            df_to_analyze['tendencia'] = slope * df_to_analyze['a帽o_num'] + intercept
            
            fig_tendencia = px.scatter(df_to_analyze, x='a帽o_num', y=Config.PRECIPITATION_COL, title='Tendencia de la Precipitaci贸n Anual')
            fig_tendencia.add_trace(go.Scatter(x=df_to_analyze['a帽o_num'], y=df_to_analyze['tendencia'], mode='lines', name='L铆nea de Tendencia', line=dict(color='red')))
            fig_tendencia.update_layout(xaxis_title="A帽o", yaxis_title="Precipitaci贸n Anual (mm)")
            st.plotly_chart(fig_tendencia, use_container_width=True)
            
            csv_data = df_to_analyze.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Descargar datos de Tendencia Anual", data=csv_data,
                file_name=f'tendencia_anual_{title_for_download}.csv', mime='text/csv',
                key='download-anual-tendencia'
            )
        else:
            st.warning("No hay suficientes datos en el per铆odo seleccionado para calcular una tendencia.")

    with mann_kendall_tab:
        st.subheader("Tendencia de Precipitaci贸n Anual (Prueba de Mann-Kendall)")
        with st.expander("驴Qu茅 es la prueba de Mann-Kendall?"):
            # --- BLOQUE CORREGIDO ---
            # La indentaci贸n de este bloque de texto ha sido reparada.
            st.markdown("""
            La **Prueba de Mann-Kendall** es un m茅todo estad铆stico no param茅trico utilizado para detectar
            tendencias en series de tiempo. No asume que los datos sigan una distribuci贸n particular.
            - **Tendencia**: Indica si es 'increasing' (creciente), 'decreasing' (decreciente) o 'no trend'.
            - **Valor p**: Si es menor a 0.05, la tendencia se considera estad铆sticamente significativa.
            - **Pendiente de Sen**: Cuantifica la magnitud de la tendencia y es robusto frente a valores at铆picos.
            """)
        
        mk_analysis_type = st.radio("Tipo de An谩lisis de Tendencia:", ["Promedio de la selecci贸n", "Estaci贸n individual"], horizontal=True, key="mk_trend_type")
        df_to_analyze_mk = None
        if mk_analysis_type == "Promedio de la selecci贸n":
            df_to_analyze_mk = df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze_mk = st.selectbox("Seleccione una estaci贸n para analizar:", options=stations_for_analysis, key="mk_station_select")
            if station_to_analyze_mk:
                df_to_analyze_mk = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_to_analyze_mk]
        
        if df_to_analyze_mk is not None and len(df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL])) > 3:
            df_clean_mk = df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
            mk_result = mk.original_test(df_clean_mk[Config.PRECIPITATION_COL])
            title = 'Promedio de la selecci贸n' if mk_analysis_type == 'Promedio de la selecci贸n' else station_to_analyze_mk
            st.markdown(f"#### Resultados para: {title}")
            col1, col2, col3 = st.columns(3)
            col1.metric("Tendencia Detectada", mk_result.trend.capitalize())
            col2.metric("Valor p", f"{mk_result.p:.4f}")
            col3.metric("Pendiente de Sen (mm/a帽o)", f"{mk_result.slope:.2f}")
            if mk_result.p < 0.05:
                st.success("La tendencia es estad铆sticamente significativa (p < 0.05).")
            else:
                st.warning("La tendencia no es estad铆sticamente significativa (p >= 0.05).")
        else:
            st.warning("No hay suficientes datos (se requieren al menos 4 puntos) para calcular la tendencia de Mann-Kendall.")

    with tendencia_tabla_tab:
        st.subheader("Tabla Comparativa de Tendencias de Precipitaci贸n Anual")
        st.info("Esta tabla resume los resultados de dos m茅todos de an谩lisis de tendencia. Presione el bot贸n para calcular los valores para todas las estaciones seleccionadas.")
        if st.button("Calcular Tendencias para Todas las Estaciones Seleccionadas"):
            with st.spinner("Calculando tendencias..."):
                results = []
                df_anual_calc = df_anual_melted.copy()
                if st.session_state.get('exclude_zeros', False):
                    df_anual_calc = df_anual_calc[df_anual_calc[Config.PRECIPITATION_COL] > 0]
                for station in stations_for_analysis:
                    station_data = df_anual_calc[df_anual_calc[Config.STATION_NAME_COL] == station].dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
                    slope_lin, p_lin = np.nan, np.nan
                    trend_mk, p_mk, slope_sen = "Datos insuficientes", np.nan, np.nan
                    if len(station_data) > 2:
                        station_data['a帽o_num'] = pd.to_numeric(station_data[Config.YEAR_COL])
                        res = stats.linregress(station_data['a帽o_num'], station_data[Config.PRECIPITATION_COL])
                        slope_lin, p_lin = res.slope, res.pvalue
                    if len(station_data) > 3:
                        mk_result_table = mk.original_test(station_data[Config.PRECIPITATION_COL])
                        trend_mk = mk_result_table.trend.capitalize()
                        p_mk = mk_result_table.p
                        slope_sen = mk_result_table.slope
                    results.append({
                        "Estaci贸n": station, "A帽os Analizados": len(station_data),
                        "Tendencia Lineal (mm/a帽o)": slope_lin, "Valor p (Lineal)": p_lin,
                        "Tendencia MK": trend_mk, "Valor p (MK)": p_mk,
                        "Pendiente de Sen (mm/a帽o)": slope_sen,
                    })
                if results:
                    results_df = pd.DataFrame(results)
                    def style_p_value(val):
                        if pd.isna(val) or isinstance(val, str): return ""
                        color = 'lightgreen' if val < 0.05 else 'lightcoral'
                        return f'background-color: {color}'
                    st.dataframe(results_df.style.format({
                        "Tendencia Lineal (mm/a帽o)": "{:.2f}", "Valor p (Lineal)": "{:.4f}",
                        "Valor p (MK)": "{:.4f}", "Pendiente de Sen (mm/a帽o)": "{:.2f}",
                    }).applymap(style_p_value, subset=['Valor p (Lineal)', 'Valor p (MK)']), use_container_width=True)

    with descomposicion_tab:
        st.subheader("Descomposici贸n de Series de Tiempo Mensual")
        station_to_decompose = st.selectbox("Seleccione una estaci贸n para la descomposici贸n:", options=stations_for_analysis, key="decompose_station_select")
        if station_to_decompose:
            df_station = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_decompose].copy()
            if not df_station.empty:
                df_station.set_index(Config.DATE_COL, inplace=True)
                try:
                    from modules.forecasting import get_decomposition_results
                    result = get_decomposition_results(df_station[Config.PRECIPITATION_COL], period=12, model='additive')
                    fig_decomp = go.Figure()
                    fig_decomp.add_trace(go.Scatter(x=df_station.index, y=df_station[Config.PRECIPITATION_COL], mode='lines', name='Original'))
                    fig_decomp.add_trace(go.Scatter(x=result.trend.index, y=result.trend, mode='lines', name='Tendencia'))
                    fig_decomp.add_trace(go.Scatter(x=result.seasonal.index, y=result.seasonal, mode='lines', name='Estacionalidad'))
                    fig_decomp.add_trace(go.Scatter(x=result.resid.index, y=result.resid, mode='lines', name='Residuo'))
                    fig_decomp.update_layout(title=f"Descomposici贸n de la Serie de Precipitaci贸n para {station_to_decompose}", height=600)
                    st.plotly_chart(fig_decomp, use_container_width=True)
                except Exception as e:
                    st.error(f"No se pudo realizar la descomposici贸n de la serie. Error: {e}")

    with autocorrelacion_tab:
        st.subheader("An谩lisis de Autocorrelaci贸n (ACF) y Autocorrelaci贸n Parcial (PACF)")
        station_to_analyze_acf = st.selectbox("Seleccione una estaci贸n:", options=stations_for_analysis, key="acf_station_select")
        max_lag = st.slider("N煤mero m谩ximo de rezagos (meses):", min_value=12, max_value=60, value=24, step=12)
        if station_to_analyze_acf:
            df_station_acf = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_analyze_acf].copy()
            if not df_station_acf.empty:
                from modules.forecasting import create_acf_chart, create_pacf_chart
                df_station_acf.set_index(Config.DATE_COL, inplace=True)
                series = df_station_acf[Config.PRECIPITATION_COL].asfreq('MS').interpolate(method='time').dropna()
                if len(series) > max_lag:
                    fig_acf = create_acf_chart(series, max_lag)
                    st.plotly_chart(fig_acf, use_container_width=True)
                    fig_pacf = create_pacf_chart(series, max_lag)
                    st.plotly_chart(fig_pacf, use_container_width=True)
                else:
                    st.warning(f"No hay suficientes datos (se requieren > {max_lag} meses) para el an谩lisis de autocorrelaci贸n.")
             
    with pronostico_sarima_tab:
        st.subheader("Pron贸stico (Modelo SARIMA)")
        station_to_forecast = st.selectbox("Seleccione una estaci贸n:", options=stations_for_analysis, key="sarima_station_select")
        
        c1, c2 = st.columns(2)
        with c1:
            forecast_horizon = st.slider("Meses a pronosticar:", 12, 36, 12, step=12, key="sarima_horizon")
        with c2:
            test_size = st.slider("Meses para evaluaci贸n:", 12, 36, 12, step=6, key="sarima_test_size", help="Usa los 煤ltimos N meses de datos hist贸ricos para medir la precisi贸n del modelo.")
        
        use_auto_arima = st.checkbox("Encontrar par谩metros 贸ptimos autom谩ticamente (Auto-ARIMA)", value=True)

        order, seasonal_order = (1,1,1), (1,1,1,12)

        if use_auto_arima:
            st.info("El modo autom谩tico buscar谩 la mejor combinaci贸n de par谩metros. El ajuste manual est谩 desactivado.", icon="")
        else:
            with st.expander("Ajuste de Par谩metros SARIMA (Manual)"):

def display_downloads_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis):
    st.header("Opciones de Descarga")
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para activar las descargas.")
        return

    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv(index=False).encode('utf-8')

    st.markdown("**Datos de Precipitaci贸n Anual (Filtrados)**")
    csv_anual = convert_df_to_csv(df_anual_melted)
    st.download_button("Descargar CSV Anual", csv_anual, 'precipitacion_anual.csv', 'text/csv', key='download-anual')

    st.markdown("**Datos de Precipitaci贸n Mensual (Filtrados)**")
    csv_mensual = convert_df_to_csv(df_monthly_filtered)
    st.download_button("Descargar CSV Mensual", csv_mensual, 'precipitacion_mensual.csv', 'text/csv', key='download-mensual')

    if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
        st.markdown("**Datos de Precipitaci贸n Mensual (Series Completadas y Filtradas)**")
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
            
        df_completed_to_download = (st.session_state.df_monthly_processed[
            (st.session_state.df_monthly_processed[Config.STATION_NAME_COL].isin(stations_for_analysis)) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year >= year_min) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year <= year_max) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
        ]).copy()
        
        csv_completado = convert_df_to_csv(df_completed_to_download)
        st.download_button("Descargar CSV con Series Completadas", csv_completado, 'precipitacion_mensual_completada.csv', 'text/csv', key='download-completado')

# Nueva funci贸n auxiliar para realizar todos los c谩lculos complejos.
# La cach茅 acelera la app, guardando el resultado de los c谩lculos.
# -----------------------------------------------------------------------------
@st.cache_data
def calculate_comprehensive_stats(df_anual, df_monthly, stations):
    """
    Calcula un conjunto completo de estad铆sticas para cada estaci贸n seleccionada.
    """
    results = []
    
    # Pre-procesa los datos mensuales para la correlaci贸n
    df_pivot_monthly = df_monthly.pivot_table(index='fecha_mes_a帽o', columns='nom_est', values='precipitation')

    for station in stations:
        stats = {"Estaci贸n": station}
        
        # Filtra datos para la estaci贸n actual
        station_anual = df_anual[df_anual['nom_est'] == station].dropna(subset=['precipitation'])
        station_monthly = df_monthly[df_monthly['nom_est'] == station].dropna(subset=['precipitation'])

        if not station_anual.empty:
            # C谩lculos anuales
            stats['A帽os con Datos'] = int(station_anual['precipitation'].count())
            stats['Ppt. Media Anual (mm)'] = station_anual['precipitation'].mean()
            stats['Desv. Est谩ndar Anual (mm)'] = station_anual['precipitation'].std()
            
            max_anual_row = station_anual.loc[station_anual['precipitation'].idxmax()]
            stats['Ppt. M谩xima Anual (mm)'] = max_anual_row['precipitation']
            stats['A帽o Ppt. M谩xima'] = int(max_anual_row['a帽o'])
            
            min_anual_row = station_anual.loc[station_anual['precipitation'].idxmin()]
            stats['Ppt. M铆nima Anual (mm)'] = min_anual_row['precipitation']
            stats['A帽o Ppt. M铆nima'] = int(min_anual_row['a帽o'])

            # C谩lculo de Tendencia (Mann-Kendall y Pendiente de Sen)
            if len(station_anual) >= 4: # Se requieren al menos 4 puntos para la tendencia
                mk_result = mk.original_test(station_anual['precipitation'])
                stats['Tendencia (mm/a帽o)'] = mk_result.slope
                stats['Significancia (p-valor)'] = mk_result.p
                # Proyecci贸n a 2040
                last_year = station_anual['a帽o'].max()
                projected_change = mk_result.slope * (2040 - last_year)
                stats['Cambio Proyectado a 2040 (mm)'] = projected_change
            else:
                stats['Tendencia (mm/a帽o)'] = np.nan
                stats['Significancia (p-valor)'] = np.nan
                stats['Cambio Proyectado a 2040 (mm)'] = np.nan

        if not station_monthly.empty:
            # C谩lculos mensuales
            max_monthly_row = station_monthly.loc[station_monthly['precipitation'].idxmax()]
            stats['Mes/A帽o Mayor Ppt.'] = max_monthly_row['fecha_mes_a帽o'].strftime('%Y-%m')
            
            min_monthly_row = station_monthly.loc[station_monthly['precipitation'].idxmin()]
            stats['Mes/A帽o Menor Ppt.'] = min_monthly_row['fecha_mes_a帽o'].strftime('%Y-%m')

            # Ppt media para cada mes
            monthly_means = station_monthly.groupby(station_monthly['fecha_mes_a帽o'].dt.month)['precipitation'].mean()
            meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']
            for i, mes in enumerate(meses, 1):
                stats[f'Ppt Media {mes} (mm)'] = monthly_means.get(i, 0)
        
        # C谩lculo de Correlaci贸n
        if len(stations) > 1:
            correlations = df_pivot_monthly.corrwith(df_pivot_monthly[station]).drop(station).dropna()
            if not correlations.empty:
                best_corr_station = correlations.idxmax()
                best_corr_value = correlations.max()
                stats['Estaci贸n Mejor Correlacionada'] = f"{best_corr_station} (r={best_corr_value:.2f})"
            else:
                stats['Estaci贸n Mejor Correlacionada'] = "N/A"
        
        results.append(stats)
        
    return pd.DataFrame(results)

def display_station_table_tab(gdf_filtered, df_anual_melted, df_monthly_filtered, stations_for_analysis, analysis_mode, selected_regions, selected_municipios, selected_altitudes, **kwargs):
    st.header("Informaci贸n Detallada de las Estaciones")
    
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros),
        analysis_mode=analysis_mode,
        selected_regions=selected_regions,
        selected_municipios=selected_municipios,
        selected_altitudes=selected_altitudes
    )

    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return

    st.info("Presiona el bot贸n para generar una tabla detallada con estad铆sticas calculadas para cada estaci贸n seleccionada.")

    if st.button(" Calcular Estad铆sticas Detalladas"):
        with st.spinner("Realizando c谩lculos, por favor espera..."):
            try:
                # Llama a la nueva funci贸n que realiza todos los c谩lculos
                detailed_stats_df = calculate_comprehensive_stats(df_anual_melted, df_monthly_filtered, stations_for_analysis)
                
                # Une los resultados con la informaci贸n geogr谩fica b谩sica
                base_info_df = gdf_filtered[['nom_est', 'alt_est', 'municipio', 'depto_region']].copy()
                base_info_df.rename(columns={'nom_est': 'Estaci贸n'}, inplace=True)
                
                final_df = pd.merge(base_info_df, detailed_stats_df, on="Estaci贸n", how="right")

                # Define el orden y formato de las columnas para una mejor visualizaci贸n
                column_order = [
                    'Estaci贸n', 'municipio', 'depto_region', 'alt_est', 'A帽os con Datos',
                    'Ppt. Media Anual (mm)', 'Desv. Est谩ndar Anual (mm)',
                    'Ppt. M谩xima Anual (mm)', 'A帽o Ppt. M谩xima', 'Ppt. M铆nima Anual (mm)', 'A帽o Ppt. M铆nima',
                    'Mes/A帽o Mayor Ppt.', 'Mes/A帽o Menor Ppt.',
                    'Tendencia (mm/a帽o)', 'Significancia (p-valor)', 'Cambio Proyectado a 2040 (mm)',
                    'Estaci贸n Mejor Correlacionada',
                    'Ppt Media Ene (mm)', 'Ppt Media Feb (mm)', 'Ppt Media Mar (mm)', 'Ppt Media Abr (mm)', 
                    'Ppt Media May (mm)', 'Ppt Media Jun (mm)', 'Ppt Media Jul (mm)', 'Ppt Media Ago (mm)',
                    'Ppt Media Sep (mm)', 'Ppt Media Oct (mm)', 'Ppt Media Nov (mm)', 'Ppt Media Dic (mm)'
                ]
                
                # Filtra las columnas que existen en el DataFrame final
                display_columns = [col for col in column_order if col in final_df.columns]
                final_df_display = final_df[display_columns]

                st.dataframe(final_df_display.style.format({
                    'Ppt. Media Anual (mm)': '{:.1f}',
                    'Desv. Est谩ndar Anual (mm)': '{:.1f}',
                    'Ppt. M谩xima Anual (mm)': '{:.1f}',
                    'Ppt. M铆nima Anual (mm)': '{:.1f}',
                    'Tendencia (mm/a帽o)': '{:.2f}',
                    'Significancia (p-valor)': '{:.3f}',
                    'Cambio Proyectado a 2040 (mm)': '{:+.1f}',
                    'Ppt Media Ene (mm)': '{:.1f}', 'Ppt Media Feb (mm)': '{:.1f}', 'Ppt Media Mar (mm)': '{:.1f}',
                    'Ppt Media Abr (mm)': '{:.1f}', 'Ppt Media May (mm)': '{:.1f}', 'Ppt Media Jun (mm)': '{:.1f}',
                    'Ppt Media Jul (mm)': '{:.1f}', 'Ppt Media Ago (mm)': '{:.1f}', 'Ppt Media Sep (mm)': '{:.1f}',
                    'Ppt Media Oct (mm)': '{:.1f}', 'Ppt Media Nov (mm)': '{:.1f}', 'Ppt Media Dic (mm)': '{:.1f}'
                }))

                # Opci贸n para descargar los datos
                csv = final_df_display.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label=" Descargar Tabla como CSV",
                    data=csv,
                    file_name='tabla_detallada_estaciones.csv',
                    mime='text/csv',
                )

            except Exception as e:
                st.error(f"Ocurri贸 un error al calcular las estad铆sticas: {e}")

def display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc):
    """Realiza y muestra el an谩lisis de sequ铆as y eventos extremos por percentiles mensuales para una estaci贸n."""
    df_long = st.session_state.get('df_long')
    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an谩lisis de percentiles. El DataFrame hist贸rico no est谩 disponible.")
        return

    st.markdown("#### Par谩metros del An谩lisis")
    col1, col2 = st.columns(2)
    p_lower = col1.slider("Percentil Inferior (Sequ铆a):", 1, 40, 10, key="p_lower_perc")
    p_upper = col2.slider("Percentil Superior (H煤medo):", 60, 99, 90, key="p_upper_perc")
    st.markdown("---")
    
    with st.spinner(f"Calculando percentiles P{p_lower} y P{p_upper} para {station_to_analyze_perc}..."):
        try:
            df_extremes, df_thresholds = calculate_percentiles_and_extremes(df_long, station_to_analyze_perc, p_lower, p_upper)
            
            year_range_val = st.session_state.get('year_range', (2000, 2020))
            if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
                year_min, year_max = year_range_val
            else:
                year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))

            df_plot = df_extremes[
                (df_extremes[Config.DATE_COL].dt.year >= year_min) &
                (df_extremes[Config.DATE_COL].dt.year <= year_max) &
                (df_extremes[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
            ].copy()

            if df_plot.empty:
                st.warning("No hay datos que coincidan con los filtros de tiempo para la estaci贸n seleccionada.")
                return

            st.subheader(f"Serie de Tiempo con Eventos Extremos (P{p_lower} y P{p_upper} Percentiles)")
            color_map = {
                f'Sequ铆a Extrema (<P{p_lower}%)': 'red',
                f'H煤medo Extremo (>P{p_upper}%)': 'blue',
                'Normal': 'gray'
            }
            
            fig_series = px.scatter(
                df_plot, x=Config.DATE_COL, y=Config.PRECIPITATION_COL,
                color='event_type',
                color_discrete_map=color_map,
                title=f"Precipitaci贸n Mensual y Eventos Extremos en {station_to_analyze_perc}",
                labels={Config.PRECIPITATION_COL: "Precipitaci贸n (mm)", Config.DATE_COL: "Fecha"},
                hover_data={'event_type': True, 'p_lower': ':.0f', 'p_upper': ':.0f'}
            )
            
            mean_precip = df_long[df_long[Config.STATION_NAME_COL] == station_to_analyze_perc][Config.PRECIPITATION_COL].mean()
            fig_series.add_hline(y=mean_precip, line_dash="dash", line_color="green", annotation_text="Media Hist贸rica")
            fig_series.update_layout(height=500)
            st.plotly_chart(fig_series, use_container_width=True)

            st.subheader("Umbrales de Percentil Mensual (Climatolog铆a Hist贸rica)")
            meses_map_inv = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
            df_thresholds['Month_Name'] = df_thresholds[Config.MONTH_COL].map(meses_map_inv)
            
            fig_thresh = go.Figure()
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_upper'], mode='lines+markers', name=f'Percentil Superior (P{p_upper}%)', line=dict(color='blue')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_lower'], mode='lines+markers', name=f'Percentil Inferior (P{p_lower}%)', line=dict(color='red')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['mean_monthly'], mode='lines', name='Media Mensual', line=dict(color='green', dash='dot')))
            
            fig_thresh.update_layout(
                title='Umbrales de Precipitaci贸n por Mes (Basado en Climatolog铆a)',
                xaxis_title="Mes", yaxis_title="Precipitaci贸n (mm)", height=400
            )
            st.plotly_chart(fig_thresh, use_container_width=True)

        except Exception as e:
            st.error(f"Error al calcular el an谩lisis de percentiles: {e}")
            st.info("Aseg煤rese de que el archivo hist贸rico de datos ('df_long') contenga datos suficientes para la estaci贸n seleccionada.")
