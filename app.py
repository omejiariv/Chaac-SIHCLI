# app.py

import streamlit as st
import geopandas as gpd
import pandas as pd
import numpy as np
import warnings
import os
from datetime import datetime
import requests_cache
import time

#--- Importaciones de M칩dulos Propios ---
from modules.config import Config
from modules.data_processor import load_and_process_all_data, complete_series, extract_elevation_from_dem, download_and_load_remote_dem
from modules.visualizer import (
    display_welcome_tab, display_spatial_distribution_tab, display_graphs_tab,
    display_advanced_maps_tab, display_anomalies_tab, display_drought_analysis_tab,
    display_stats_tab, display_correlation_tab, display_enso_tab,
    display_trends_and_forecast_tab, display_downloads_tab, display_station_table_tab,
    display_forecast_tab
)
from modules.reporter import generate_pdf_report
from modules.analysis import calculate_monthly_anomalies
from modules.analysis import calculate_basin_stats
from modules.github_loader import load_csv_from_url, load_zip_from_url

#--- Desactivar Advertencias ---
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

def apply_filters_to_stations(df, min_perc, altitudes, regions, municipios, celdas):
    """Aplica una serie de filtros al DataFrame de estaciones."""
    stations_filtered = df.copy()
    if Config.PERCENTAGE_COL in stations_filtered.columns:
        stations_filtered[Config.PERCENTAGE_COL] = pd.to_numeric(
            stations_filtered[Config.PERCENTAGE_COL].astype(str).str.replace(',', '.', regex=False), 
            errors='coerce'
        ).fillna(0)
    if min_perc > 0:
        stations_filtered = stations_filtered[stations_filtered[Config.PERCENTAGE_COL] >= min_perc]
    if altitudes:
        conditions = []
        altitude_col_numeric = pd.to_numeric(stations_filtered[Config.ALTITUDE_COL], errors='coerce')
        for r in altitudes:
            if r == '0-500': conditions.append((altitude_col_numeric >= 0) & (altitude_col_numeric <= 500))
            elif r == '500-1000': conditions.append((altitude_col_numeric > 500) & (altitude_col_numeric <= 1000))
            elif r == '1000-2000': conditions.append((altitude_col_numeric > 1000) & (altitude_col_numeric <= 2000))
            elif r == '2000-3000': conditions.append((altitude_col_numeric > 2000) & (altitude_col_numeric <= 3000))
            elif r == '>3000': conditions.append(altitude_col_numeric > 3000)
        if conditions:
            stations_filtered = stations_filtered[pd.concat(conditions, axis=1).any(axis=1)]
    if regions:
        stations_filtered = stations_filtered[stations_filtered[Config.REGION_COL].isin(regions)]
    if municipios:
        stations_filtered = stations_filtered[stations_filtered[Config.MUNICIPALITY_COL].isin(municipios)]
    if celdas and Config.CELL_COL in stations_filtered.columns:
        stations_filtered = stations_filtered[stations_filtered[Config.CELL_COL].isin(celdas)]
    return stations_filtered

def main():
    # --- Definiciones de Funciones Internas ---
    def process_and_store_data(file_mapa, file_precip, file_shape):
        with st.spinner("Procesando archivos y cargando datos..."):
            gdf_stations, gdf_municipios, df_long, df_enso, gdf_subcuencas = \
                load_and_process_all_data(file_mapa, file_precip, file_shape)

            if gdf_stations is not None and df_long is not None and gdf_municipios is not None:
                st.session_state.update({
                    'gdf_stations': gdf_stations, 'gdf_municipios': gdf_municipios,
                    'df_long': df_long, 'df_enso': df_enso,
                    'gdf_subcuencas': gdf_subcuencas,
                    'data_loaded': True
                })
                st.success("춰Datos cargados y listos!")
                st.rerun()
            else:
                st.error("Hubo un error al procesar los archivos.")
                st.session_state['data_loaded'] = False

    def display_map_controls(container_object, key_prefix):
        base_map_options = {
            "CartoDB Positron": {"tiles": "cartodbpositron", "attr": "CartoDB"},
            "OpenStreetMap": {"tiles": "OpenStreetMap", "attr": "OpenStreetMap"},
            "Topograf칤a (Open TopoMap)": {
                "tiles": "https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png",
                "attr": "Open TopoMap"
            },
        }
        overlay_map_options = {
            "Mapa de Colombia (WMS IDEAM)": {
                "url": "https://geoservicios.ideam.gov.co/geoserver/ideam/wms",
                "layers": "ideam:col_admin",
                "fmt": 'image/png',
                "transparent": True,
                "attr": "IDEAM",
                "overlay": True
            }
        }
        selected_base_map_name = container_object.selectbox(
            "Seleccionar Mapa Base",
            list(base_map_options.keys()),
            key=f"{key_prefix}_base_map"
        )
        selected_overlays_names = container_object.multiselect(
            "Seleccionar Capas Adicionales",
            list(overlay_map_options.keys()),
            key=f"{key_prefix}_overlays"
        )
        selected_base_map_config = base_map_options[selected_base_map_name]
        selected_overlays_config = [overlay_map_options[name] for name in selected_overlays_names]
        return selected_base_map_config, selected_overlays_config

    # --- Inicio de la Ejecuci칩n de la App ---
    st.set_page_config(layout="wide", page_title=Config.APP_TITLE)
    st.markdown("""<style>div.block-container{padding-top:1rem;} [data-testid="stMetricValue"] {font-size:1.8rem;} [data-testid="stMetricLabel"] {font-size: 1rem; padding-bottom:5px; } button [data-baseweb="tab"] {font-size:16px;font-weight:bold;color:#333;}</style>""", unsafe_allow_html=True)
    Config.initialize_session_state()

    # --- Gu칤a Interactiva ---
    if 'first_visit' not in st.session_state:
        st.session_state.first_visit = True
    if not st.session_state.get('data_loaded', False) and st.session_state.first_visit:
        st.toast("춰Bienvenido a Chaac SIHCLI! 游녦")
        time.sleep(1.5)
        st.toast("Para empezar, carga tus datos desde GitHub...")
        time.sleep(2)
        st.toast("...o sube tus archivos manualmente en el panel de la izquierda. 游녣")
        st.session_state.first_visit = False

    progress_placeholder = st.empty()
    title_col1, title_col2 = st.columns([0.05, 0.95])
    with title_col1:
        if os.path.exists(Config.LOGO_PATH):
            st.image(Config.LOGO_PATH, width=60)
    with title_col2:
        st.markdown(f'<h1 style="font-size:28px; margin-top:1rem;">{Config.APP_TITLE}</h1>', unsafe_allow_html=True)

    # --- Panel de Control (Sidebar) ---
    st.sidebar.header("Panel de Control")
    with st.sidebar.expander("**Subir/Actualizar Archivos Base**", expanded=not st.session_state.get('data_loaded', False)):

        load_mode = st.radio("Modo de Carga", ("GitHub", "Manual"), key="load_mode", horizontal=True)
        if load_mode == "Manual":
            uploaded_file_mapa = st.file_uploader("1. Archivo de estaciones (CSV)", type="csv")
            uploaded_file_precip = st.file_uploader("2. Archivo de precipitaci칩n (CSV)", type="csv")
            uploaded_zip_shapefile = st.file_uploader("3. Shapefile de municipios (.zip)", type="zip")
            if st.button("Procesar Datos Manuales"):
                if all([uploaded_file_mapa, uploaded_file_precip, uploaded_zip_shapefile]):
                    process_and_store_data(uploaded_file_mapa, uploaded_file_precip, uploaded_zip_shapefile)
                else:
                    st.warning("Por favor, suba los tres archivos requeridos.")
        else:
            st.info(f"Datos desde: **{Config.GITHUB_USER}/{Config.GITHUB_REPO}**")
            if st.button("Cargar Datos desde GitHub"):
                with st.spinner("Descargando archivos..."):
                    github_files = {
                        'mapa': load_csv_from_url(Config.URL_ESTACIONES_CSV),
                        'precip': load_csv_from_url(Config.URL_PRECIPITACION_CSV),
                        'shape': load_zip_from_url(Config.URL_SHAPEFILE_ZIP)
                    }
                    if all(github_files.values()):
                        process_and_store_data(github_files['mapa'], github_files['precip'], github_files['shape'])
                    else:
                        st.error("No se pudieron descargar los archivos desde GitHub.")

    if not st.session_state.get('data_loaded', False):
        display_welcome_tab()
        st.warning("Para comenzar, cargue los datos usando el panel de la izquierda.")
        return

    st.sidebar.success("Datos cargados.")
    if st.sidebar.button("Limpiar Cach칠 y Reiniciar"):
        st.cache_data.clear()
        st.cache_resource.clear()
        requests_cache.clear()
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

    with st.sidebar.expander("**1. Filtros Geogr치ficos y de Datos**", expanded=True):
        # ... (c칩digo de filtros sin cambios) ...
        min_data_perc = st.slider("Filtrar por % de datos m칤nimo:", 0, 100, st.session_state.get('min_data_perc_slider', 0))
        altitude_ranges = ['0-500', '500-1000', '1000-2000', '2000-3000', '>3000']
        selected_altitudes = st.multiselect('Filtrar por Altitud (m)', options=altitude_ranges)
        regions_list = sorted(st.session_state.gdf_stations[Config.REGION_COL].dropna().unique())
        selected_regions = st.multiselect('Filtrar por Depto/Regi칩n', options=regions_list, key='regions_multiselect')
        temp_gdf_for_mun = st.session_state.gdf_stations.copy()
        if selected_regions:
            temp_gdf_for_mun = temp_gdf_for_mun[temp_gdf_for_mun[Config.REGION_COL].isin(selected_regions)]
        municipios_list = sorted(temp_gdf_for_mun[Config.MUNICIPALITY_COL].dropna().unique())
        selected_municipios = st.multiselect('Filtrar por Municipio', options=municipios_list, key='municipios_multiselect')
        celdas_list = sorted(temp_gdf_for_mun[Config.CELL_COL].dropna().unique()) if Config.CELL_COL in temp_gdf_for_mun.columns else []
        selected_celdas = st.multiselect('Filtrar por Celda_XY', options=celdas_list, key='celdas_multiselect')
        gdf_filtered = apply_filters_to_stations(st.session_state.gdf_stations, min_data_perc, selected_altitudes, selected_regions, selected_municipios, selected_celdas)


    with st.sidebar.expander("**2. Selecci칩n de Estaciones y Per칤odo**", expanded=True):
        # ... (c칩digo de selecci칩n de estaciones y per칤odo sin cambios) ...
        stations_options = sorted(gdf_filtered[Config.STATION_NAME_COL].unique())
        def select_all_stations():
            if st.session_state.get('select_all_checkbox_main', False):
                st.session_state.station_multiselect = stations_options
            else:
                st.session_state.station_multiselect = []
        st.checkbox("Seleccionar/Deseleccionar todas", key='select_all_checkbox_main', on_change=select_all_stations)
        selected_stations = st.multiselect('Seleccionar Estaciones', options=stations_options, key='station_multiselect')
        years_with_data = sorted(st.session_state.df_long[Config.YEAR_COL].dropna().unique())
        year_range_default = (min(years_with_data), max(years_with_data)) if years_with_data else (1970, 2020)
        year_range = st.slider("Rango de A침os", min_value=year_range_default[0], max_value=year_range_default[1], value=st.session_state.get('year_range', year_range_default), key='year_range')
        meses_dict = {m: i + 1 for i, m in enumerate(['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre'])}
        meses_nombres = st.multiselect("Meses", list(meses_dict.keys()), default=list(meses_dict.keys()))
        meses_numeros = [meses_dict[m] for m in meses_nombres]

    with st.sidebar.expander("Opciones de Preprocesamiento"):
        st.radio("Modo de an치lisis", ("Usar datos originales", "Completar series (interpolaci칩n)"), key="analysis_mode")
        st.checkbox("Excluir datos nulos (NaN)", key='exclude_na')
        st.checkbox("Excluir valores cero (0)", key='exclude_zeros')

    # --- Definici칩n de Pesta침as ---
    tab_names = [
        "Bienvenida", "Distribuci칩n Espacial", "Gr치ficos", "Mapas Avanzados",
        "An치lisis de Anomal칤as", "An치lisis de Extremos", "Estad칤sticas",
        "Correlaci칩n", "An치lisis ENSO", "Tendencias y Pron칩sticos",
        "Pron칩stico del Tiempo", "Descargas", "An치lisis por Cuenca",
        "Tabla de Estaciones", "Generar Reporte"
    ]
    tabs = st.tabs(tab_names)

    stations_for_analysis = selected_stations

    if not stations_for_analysis:
        with tabs[0]:
            display_welcome_tab()
        st.info("Para comenzar, seleccione al menos una estaci칩n en el panel de la izquierda.")
        for tab in tabs[1:]:
            with tab:
                st.info("Seleccione al menos una estaci칩n para ver el contenido.")
        return

    # --- Procesamiento de Datos Post-Filtros ---
    df_monthly_filtered = st.session_state.df_long[
        (st.session_state.df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)) &
        (st.session_state.df_long[Config.DATE_COL].dt.year >= year_range[0]) &
        (st.session_state.df_long[Config.DATE_COL].dt.year <= year_range[1]) &
        (st.session_state.df_long[Config.DATE_COL].dt.month.isin(meses_numeros))
    ].copy()

    if st.session_state.analysis_mode == "Completar series (interpolaci칩n)":
        bar = progress_placeholder.progress(0, text="Iniciando interpolaci칩n...")
        df_monthly_filtered = complete_series(df_monthly_filtered, _progress_bar=bar)
        progress_placeholder.empty()

    if st.session_state.get('exclude_na', False):
        df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL], inplace=True)
    if st.session_state.get('exclude_zeros', False):
        df_monthly_filtered = df_monthly_filtered[df_monthly_filtered[Config.PRECIPITATION_COL] > 0]

    annual_agg = df_monthly_filtered.groupby([Config.STATION_NAME_COL, Config.YEAR_COL]).agg(
        precipitation_sum=(Config.PRECIPITATION_COL, 'sum'),
        meses_validos=(Config.MONTH_COL, 'nunique')
    ).reset_index()
    annual_agg.loc[annual_agg['meses_validos'] < 10, 'precipitation_sum'] = np.nan
    df_anual_melted = annual_agg.rename(columns={'precipitation_sum': Config.PRECIPITATION_COL})

    display_args = {
        "gdf_filtered": gdf_filtered, "stations_for_analysis": stations_for_analysis,
        "df_anual_melted": df_anual_melted, "df_monthly_filtered": df_monthly_filtered,
        "analysis_mode": st.session_state.analysis_mode, "selected_regions": selected_regions,
        "selected_municipios": selected_municipios, "selected_altitudes": selected_altitudes
    }

    # --- Renderizado de Pesta침as ---
    with tabs[0]: display_welcome_tab()
    with tabs[1]: display_spatial_distribution_tab(**display_args)
    with tabs[2]: display_graphs_tab(**display_args)
    with tabs[3]: display_advanced_maps_tab(**display_args)
    with tabs[4]: display_anomalies_tab(df_long=st.session_state.df_long, **display_args)
    with tabs[5]: display_drought_analysis_tab(**display_args)
    with tabs[6]: display_stats_tab(df_long=st.session_state.df_long, **display_args)
    with tabs[7]: display_correlation_tab(**display_args)
    with tabs[8]: display_enso_tab(df_enso=st.session_state.df_enso, **display_args)
    with tabs[9]: display_trends_and_forecast_tab(df_full_monthly=st.session_state.df_long, **display_args)
    with tabs[10]: display_forecast_tab(**display_args)
    with tabs[11]: display_downloads_tab(
        df_anual_melted=df_anual_melted, df_monthly_filtered=df_monthly_filtered,
        stations_for_analysis=stations_for_analysis,
        analysis_mode=st.session_state.analysis_mode
    )

    # --- PESTA칌A NUEVA: AN츼LISIS POR CUENCA ---
    with tabs[12]:
        st.header("An치lisis Agregado por Cuenca Hidrogr치fica")
        if st.session_state.gdf_subcuencas is not None and not st.session_state.gdf_subcuencas.empty:
            BASIN_NAME_COLUMN = 'SUBC_LBL'
            if BASIN_NAME_COLUMN in st.session_state.gdf_subcuencas.columns:
                relevant_basins_gdf = gpd.sjoin(st.session_state.gdf_subcuencas, gdf_filtered, how="inner", predicate="intersects")
                if not relevant_basins_gdf.empty:
                    basin_names = sorted(relevant_basins_gdf[BASIN_NAME_COLUMN].dropna().unique())
                else:
                    basin_names = []

                if not basin_names:
                    st.info("Ninguna cuenca contiene estaciones que coincidan con los filtros actuales.")
                else:
                    selected_basin = st.selectbox(
                        "Seleccione una cuenca para analizar:",
                        options=basin_names,
                        key="basin_selector"
                    )
                    if selected_basin:
                        stats_df, stations, error_msg = calculate_basin_stats(
                            gdf_filtered,
                            st.session_state.gdf_subcuencas,
                            df_monthly_filtered,
                            selected_basin,
                            BASIN_NAME_COLUMN
                        )
                        if error_msg: st.warning(error_msg)
                        if stations:
                            st.subheader(f"Resultados para la cuenca: {selected_basin}")
                            st.metric("N칰mero de Estaciones en la Cuenca", len(stations))
                            with st.expander("Ver estaciones incluidas"): st.write(", ".join(stations))
                            if not stats_df.empty:
                                st.markdown("---")
                                st.write("**Estad칤sticas de Precipitaci칩n Mensual (Agregada)**")
                                st.dataframe(stats_df, use_container_width=True)
                            else:
                                st.info("Aunque se encontraron estaciones, no hay datos de precipitaci칩n para el per칤odo seleccionado.")
                        else:
                            st.warning("No se encontraron estaciones dentro de la cuenca seleccionada.")
            else:
                st.error(f"Error Cr칤tico: No se encontr칩 la columna de nombres '{BASIN_NAME_COLUMN}' en el archivo de subcuencas.")
        else:
            st.warning("Los datos de las subcuencas no est치n cargados.")

    with tabs[13]: display_station_table_tab(**display_args)

    with tabs[14]:
        # ... (c칩digo de la pesta침a "Generar Reporte" sin cambios) ...
        st.header("Generaci칩n de Reporte PDF")
        report_title = st.text_input("T칤tulo del Reporte:", value="An치lisis Hidroclim치tico")
        report_sections_options = [
            "Resumen Ejecutivo", "Tabla de Estaciones", "Distribuci칩n Espacial",
            "Gr치ficos de Series Temporales", "Mapas Avanzados de Interpolaci칩n",
            "An치lisis de Anomal칤as", "An치lisis de Extremos Hidrol칩gicos",
            "Estad칤sticas Descriptivas", "An치lisis de Correlaci칩n",
            "An치lisis de El Ni침o/La Ni침a (ENSO)", "An치lisis de Tendencias y Pron칩sticos",
            "Disponibilidad de Datos", "Metodolog칤a y Fuentes de Datos"
        ]
        st.markdown("**Seleccione las secciones a incluir:**")
        def select_all_report_sections_on_change():
            if st.session_state.select_all_report_sections_checkbox:
                st.session_state.selected_report_sections_multiselect = report_sections_options
            else:
                st.session_state.selected_report_sections_multiselect = []
        st.checkbox(
            "Seleccionar/Deseleccionar todas",
            key='select_all_report_sections_checkbox',
            on_change=select_all_report_sections_on_change
        )
        selected_report_sections = st.multiselect(
            "Secciones a incluir:",
            options=report_sections_options,
            key='selected_report_sections_multiselect'
        )
        if st.button("Generar Reporte PDF"):
            if not selected_report_sections:
                st.warning("Seleccione al menos una secci칩n.")
            else:
                with st.spinner("Generando reporte..."):
                    try:
                        summary_data = {
                            "Estaciones": f"{len(stations_for_analysis)}/{len(st.session_state.gdf_stations)}",
                            "Periodo": f"{year_range[0]}-{year_range[1]}",
                            "Modo de An치lisis": st.session_state.analysis_mode
                        }
                        df_anomalies = calculate_monthly_anomalies(df_monthly_filtered, st.session_state.df_long)
                        report_pdf_bytes = generate_pdf_report(
                            report_title=report_title,
                            sections_to_include=selected_report_sections,
                            summary_data=summary_data,
                            df_anomalies=df_anomalies,
                            **display_args
                        )
                        st.download_button(
                            label="Descargar Reporte PDF",
                            data=report_pdf_bytes,
                            file_name=f"{report_title.replace(' ', '_')}.pdf",
                            mime="application/pdf"
                        )
                        st.success("춰Reporte generado!")
                    except Exception as e:
                        st.error(f"Error al generar el reporte: {e}")
                        st.exception(e)
                        
if __name__ == "__main__":
    main()
